
var documents = [{
    "id": 0,
    "url": "/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "/about",
    "title": "我的博客",
    "body": "关于我的博客 "
    }, {
    "id": 2,
    "url": "/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 3,
    "url": "/",
    "title": "Home",
    "body": "      {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 4,
    "url": "/page2/",
    "title": "Home",
    "body": "      {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 5,
    "url": "/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 6,
    "url": "/Python/",
    "title": "Python",
    "body": "2021/06/04 - python 性能问题字典、列表、元组初始化用 {} [] () 还是 dict() list() tuple(): 1234567import timeitprint(timeit. timeit(stmt='{}', number=10000000))print(timeit. timeit(stmt='dict()', number=10000000))输出：0. 16547880. 830841234567import timeitprint(timeit. timeit(stmt='[]', number=10000000))print(timeit. timeit(stmt='list()', number=10000000))输出：0. 18168670. 84091571234567import timeitprint(timeit. timeit(stmt='()', number=10000000))print(timeit. timeit(stmt='tuple()', number=10000000))输出：0. 10895270. 5617243Python 语法 字典直接根据下标取值，如果下标对应的值不存在，会报错（和C++不同）"
    }, {
    "id": 7,
    "url": "/Golang/",
    "title": "Golang",
    "body": "2021/04/11 - 1、Go 语言简介 Go 语言起源 2007 年，并于 2009 年正式对外发布 Go 语言三位作者：     Robert Griesemer，参与开发 Java HotSpot 虚拟机；   Rob Pike，Go 语言项目总负责人，贝尔实验室 Unix 团队成员，参与的项目包括 Plan 9，Inferno 操作系统和 Limbo 编程语言；   Ken Thompson，贝尔实验室 Unix 团队成员，C 语言、Unix 和 Plan 9 的创始人之一，与 Rob Pike 共同开发了 UTF-8 字符集规范    为什么要创造一门编程语言：     C/C++ 的发展速度无法跟上计算机发展的脚步，十多年来也没有出现一门与时代相符的主流系统编程语言，因此人们需要一门新的系统编程语言来弥补这个空缺，尤其是在计算机信息时代。   相比计算机性能的提升，软件开发领域不被认为发展得足够快或者比硬件发展得更加成功（有许多项目均以失败告终），同时应用程序的体积始终在不断地扩大，这就迫切地需要一门具备更高层次概念的低级语言来突破现状。   在 Go 语言出现之前，开发者们总是面临非常艰难的抉择，究竟是使用执行速度快但是编译速度并不理想的语言（如：C++），还是使用编译速度较快但执行效率不佳的语言（如：. NET、Java），或者说开发难度较低但执行速度一般的动态语言呢？显然，Go 语言在这 3 个条件之间做到了最佳的平衡：==快速编译，高效执行，易于开发==。    Hello World1234567package main  // Go 程序都组织成包import  fmt   // import 语句用于导入外部代码。标准库中的 fmt 包用于格式化并输出数据func main() {  // 像 C 语言一样，main 函数是程序执行的入口  fmt. Println( Hello World! )}2、基本结构与数据类型2. 1 文件名、关键字、标识符:  文件后缀名为 . go，由小写字母组成，如果有多个部分，用 _ 分隔，如 fmt_test. go go语言关键字只有25个：break, default, func, interface, select, case, defer, go, map, struct, chan, else, goto, package, switch, const, fallthrough, if, range, type, continue, for, import, return, var 还有 36 个预定义标识符：append, bool, byte, cap, close, complex, complex64, complex128, uint16, copy, false, float32, float64, imag, int, int8, int16, uint32, int32, int64, iota, len, make, new, nil, panic, uint64, print, println, real, recover, string, true, uint, uint8, uintptr 有效的标识符必须以字母（可以使用任何 UTF-8 编码的字符或 _）开头，然后紧跟着 0 个或多个字符或 Unicode 数字，如：X56、group1、_x23、i、өԑ12。2. 2 包的概念、导入与可见性:  如同其它一些编程语言中的类库或命名空间的概念，每个 Go 文件都属于且仅属于一个包。一个包可以由许多以 . go 为扩展名的源文件组成，因此文件名和包名一般来说都是不相同的。 必须在源文件中非注释的第一行指明这个文件属于哪个包，如：package main。package main表示一个可独立执行的程序，每个 Go 应用程序都包含一个名为 main 的包。 如果对一个包进行更改或重新编译，所有引用了这个包的程序都必须全部重新编译。 导入包的方式：12import  fmt import  os 1234import (   fmt    os ) 可见性规则：     当标识符（包括常量、变量、类型、函数名、结构字段等等）以一个大写字母开头，如：Group1，那么使用这种形式的标识符的对象就可以被外部包的代码所使用（客户端程序需要先导入这个包），这被称为导出（像面向对象语言中的 public）   标识符如果以小写字母开头，则对包外是不可见的，但是他们在整个包的内部是可见并且可用的（像面向对象语言中的 private ）。    可以通过使用包的别名来解决包名之间的名称冲突，如：import fm  fmt  如果导入了一个包却没有使用它，则在编译时会报错，如： os  imported but not used2. 3 注释:  使用和 C 语言一样的注释方式，// 表示单行注释，/**/ 表示多行注释或块注释2. 4 类型与运算符:  Go 语言类型包括：int、float32、 float64、bool、string、struct、array、slice、map、channel、interface。12345678910111213141516与操作系统架构无关的类型都有固定的大小，并在类型的名称中就可以看出来：整数：int8（-128 -&gt; 127）int16（-32768 -&gt; 32767）int32（-2,147,483,648 -&gt; 2,147,483,647）int64（-9,223,372,036,854,775,808 -&gt; 9,223,372,036,854,775,807）无符号整数：uint8（0 -&gt; 255）uint16（0 -&gt; 65,535）uint32（0 -&gt; 4,294,967,295）uint64（0 -&gt; 18,446,744,073,709,551,615）浮点型（IEEE-754 标准）：float32（+- 1e-45 -&gt; +- 3. 4 * 1e38）float64（+- 5 1e-324 -&gt; 107 1e308） 位运算：&amp;、|、^、&amp;^(位清除：将指定位置上的值设置为 0) 一元运算符：&lt;&lt;、&gt;&gt; 逻辑运算符：==、!=、&lt;、&lt;=、&gt;、&gt;= 算术运算符：+、-、*、/、%12345678优先级   运算符 7     ^ ! 6     * / % &lt;&lt; &gt;&gt; &amp; &amp;^ 5     + - | ^ 4     == != &lt; &lt;= &gt;= &gt; 3     &lt;- 2     &amp;&amp; 1     || 类型别名：type newType orgType，如 type AGE int3、变量、常量、指针3. 1 变量:  声明变量的一般形式是使用 var 关键字：var identifier type。 为什么将变量类型放到变量名后面：避免像 C 语言中那样含糊不清的声明形式，例如：int* a, b。 当一个变量被声明之后，系统自动赋予它该类型的零值：int 为 0，float 为 0. 0，bool 为 false，string 为空字符串，指针为 nil。123456789101112131415161718var a int = 1// Go 编译器可以根据变量的值来自动推断其类型，在编译时经完成推断过程var b = 15var c = false// 在函数体内声明局部变量时，可使用简短声明语法 :=，不可以用于全局变量的声明与赋值d := true// 同一类型的多个变量可以声明在同一行var e, f intd, e, f = false, 1, 2// 多个变量使用 := 声明并初始化g, h :=  abc , false// 交换2个变量的值e, f = f, e 值类型和引用类型：     int、float、bool、string、数组、结构体属于值类型   指针、slice、map、channel 属于引用类型   3. 2 常量:  常量使用关键字 const 定义，用于存储不会改变的数据。常量的定义格式：const identifier [type] = value12const b string =  abc  // 显式类型定义const b =  abc      // 隐式类型定义 常量还可以用作枚举：12345const (  Unknown = 0  Female = 1  Male = 2) iota 使用方法：12345678910111213141516171819202122232425262728293031// 第一个 iota 等于 0，每当 iota 在新的一行被使用时，它的值都会自动加 1，// 并且没有赋值的常量默认会应用上一行的赋值表达式：const (  a = iota  // a = 0  b = iota  // b = 1  c = iota  // c = 2)// 赋值一个常量时，之后没赋值的常量都会应用上一行的赋值表达式const (  a = iota // a = 0  b     // b = 1  c     // c = 2  d = 5   // d = 5  e     // e = 5)// 赋值两个常量，iota 只会增长一次，而不会因为使用了两次就增长两次const (  Apple, Banana = iota + 1, iota + 2 // Apple=1 Banana=2  Cherimoya, Durian         // Cherimoya=2 Durian=3  Elderberry, Fig          // Elderberry=3, Fig=4)const (  _ = iota            // 使用 _ 忽略不需要的 iota  KB = 1 &lt;&lt; (10 * iota)     // 1 &lt;&lt; (10*1)  MB               // 1 &lt;&lt; (10*2)  GB               // 1 &lt;&lt; (10*3)  TB               // 1 &lt;&lt; (10*4))4、控制结构4. 1 if-else 结构: 12345678a, b := 1, 2if a &gt; b {	fmt. Println( a &gt; b )} else if a &lt; b {	fmt. Println( a &lt; b )} else {	fmt. Println( a == b )} if 和 else 之后的 { 必须和关键字同一行，否则编译会报错：syntax error: unexpected newline, expecting { after if clause4. 2 switch结构: 1234567891011121314151617181920212223242526272829// 第一种形式switch variable {	case value1:		fmt. Println( case value1 )	// 这里没有 break	case value2:		fmt. Println( case value2 )	default:		fmt. Println( default )}// 第二种形式，case 中进行条件判断switch {  case i &lt; 0:    f1()  case i == 0:    f2()  case i &gt; 0:    f3()}// 第三种形式，包含一个初始化语句switch result := calculate(); {  case result &lt; 0:    . . .   case result &gt; 0:    . . .   default:    . . . } 变量 variable 可以是任何类型，而 value1 和 value2 则可以是同类型的任意值。类型不被局限于常量或整数，但必须是相同的类型；或者最终结果为相同类型的表达式。前花括号 { 必须和 switch 关键字在同一行。 如果在执行完每个分支的代码后，还希望继续执行后续分支的代码，可以使用 fallthrough 关键字来达到目的。12345switch i {  case 0: fallthrough  case 1:    f() // 当 i == 0 时函数也会被调用}4. 3 for 结构: 1234567891011121314151617181920// 基本形式for i := 0; i &lt; 5; i++ {  fmt. Printf( This is the %d iteration\n , i)}// 基于条件判断的迭代，类似于其他语言的 whilevar i int = 5for i &gt;= 0 {	i = i - 1	fmt. Printf( The variable i is now: %d\n , i)}// 无限循环for {	// do something	// 需要退出循环，用 break}// for-range 结构1、go基本语法，常用容器：数组，slice，map，（ 第2、4章和文档） "
    }, {
    "id": 8,
    "url": "/SystemDesign/",
    "title": "系统设计",
    "body": "2021/02/26 - 1、高并发: https://snailclimb. gitee. io/javaguide/#/?id=%e9%ab%98%e5%b9%b6%e5%8f%91 1. 1、负载均衡: 根据节点负载情况，将客户端请求发送到不同的节点。常用的负载均衡算法如下：  轮询 加权轮询 最少连接数 随机 源地址哈希（IP Hash）1. 2、缓存: 网站性能优化的第一定律：有限考虑使用缓存。 1. 3、消息队列: 1. 3. 1、模型:  点对点模式：一个消息只能被一个消费者消费一次。 发布订阅模式：多个订阅者可以从频道订阅这条消息并消费。1. 3. 2、使用场景:  异步处理：例如用户注册发送奖励。 流量削锋：服务器根据处理能力从消息队列中获取消息处理。防止短时间内大量请求压垮服务器。 应用解藕：一个模块修改不影响其他模块，实现可扩展性。1. 3. 3、可靠性:  发送端可靠性：使用本地消息表，发送成功删除本地消息，失败继续发送。 接收端可靠性：消费端业务逻辑幂等性；消息具有唯一编号。并使用一张日志表记录已经消费的消息编号。1. 4、读写分离、分库分表:  读写分离可以大幅提高读性能，小幅提高写的性能 分库分表是为了解决由于库、表数据量过大，而导致数据库性能持续下降的问题。2、高可用: https://snailclimb. gitee. io/javaguide/#/?id=%e9%ab%98%e5%8f%af%e7%94%a8 2. 1 降级:  服务降级是指系统为了应对大量的请求，主动关闭部分功能，以此释放服务器资源从而保证核心功能可用。2. 2 限流:  限流(Ratelimiting)是指对服务的请求进行限制，例如某一接口的请求限制为 100 个每秒,对超过限制的请求则进行快速失败或丢弃。 常见限流算法（https://www. infoq. cn/article/Qg2tX8fyw5Vt-f3HH673）     漏桶算法   令牌桶算法   2. 3 熔断: 分布式id生成算法:  uuid 数据库自增id snowflake：41bit时间戳 + 10bit机器id + 12bit序列号分布式系统如何保证一致性: reactor模式: https://cloud. tencent. com/developer/article/1488120 无论是C++还是Java编写的网络框架，大多数都是基于Reactor模型进行设计和开发，Reactor模型基于事件驱动，特别适合处理海量的I/O事件。 Reactor模型中定义的三种角色：  Reactor：负责监听和分配事件，将I/O事件分派给对应的Handler。新的事件包含连接建立就绪、读就绪、写就绪等。 Acceptor：处理客户端新连接，并分派请求到处理器链中。 Handler：将自身与事件绑定，执行非阻塞读/写任务，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。可用资源池来管理。微博粉丝关系设计: "
    }, {
    "id": 9,
    "url": "/Zookeeper/",
    "title": "Zookeeper",
    "body": "2021/02/09 - 什么是Zookeeper: https://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653193977&amp;idx=1&amp;sn=12319f8cb81f55a40ac461bd0ad9d74e&amp;chksm=8c99f423bbee7d35056ce7ec1b321f33aad15c309de6eba0086cb31a48b975ccb1d695d5a251&amp;scene=21#wechat_redirect  Zookeeper是一个分布式协调服务，可以在分布式系统中共享配置，协调锁资源，提供命名服务。 Zookeeper的数据模型很像数据结构当中的树，也很像文件系统的目录。 Zookeeper的数据存储基于节点，这种节点叫做Znode。Znode包含了数据、子节点引用、访问权限等等。     data：Znode存储的数据信息。   ACL：记录Znode的访问权限，即哪些人或哪些IP可以访问本节点。   stat：包含Znode的各种元数据，比如事务ID、版本号、时间戳、大小等等。   child：当前节点的子节点引用，类似于二叉树的左孩子右孩子。    Zookeeper是为读多写少的场景所设计。Znode并不是用来存储大规模业务数据，而是用于存储少量的状态和配置信息，每个节点的数据最大不能超过1MB。 Zookeeper包含的基本操作：     create：创建节点   delete：删除节点   exists：判断节点是否存在   getData：获得一个节点的数据   setData：设置一个节点的数据   getChildren：获取节点下的所有子节点    Zookeeper客户端在请求读操作的时候，可以选择是否设置Watch。Watch可以理解成是注册在特定Znode上的触发器。当这个Znode发生改变，也就是调用了create，delete，setData方法的时候，将会触发Znode上注册的对应事件，请求Watch的客户端会接收到异步通知。Zookeeper的一致性:  Zookeeper Service集群是一主多从结构。 在更新数据时，首先更新到主节点（这里的节点是指服务器，不是Znode），再同步到从节点。 在读取数据时，直接读取任意从节点。 为了保证主从节点的数据一致性，Zookeeper采用了ZAB（ZooKeeper Atomic Broadcast）协议，这种协议非常类似于一致性算法Paxos和Raft。 ZAB协议所定义的三种节点状态：     Looking ：选举状态。   Following ：Follower节点（从节点）所处的状态。   Leading ：Leader节点（主节点）所处状态。    最大ZXID也就是节点本地的最新事务编号，包含epoch和计数两部分。epoch是纪元的意思，相当于Raft算法选主时候的term。ZAB的崩溃恢复:  假如Zookeeper当前的主节点挂掉了，集群会进行崩溃恢复。ZAB的崩溃恢复分成三个阶段：1、Leader election 选举阶段，此时集群中的节点处于Looking状态。它们会各自向其他节点发起投票，投票当中包含自己的服务器ID和最新事务ID（ZXID）。 接下来，节点会用自身的ZXID和从其他节点接收到的ZXID做比较，如果发现别人家的ZXID比自己大，也就是数据比自己新，那么就重新发起投票，投票给目前已知最大的ZXID所属节点。 每次投票后，服务器都会统计投票数量，判断是否有某个节点得到半数以上的投票。如果存在这样的节点，该节点将会成为准Leader，状态变为Leading。其他节点的状态变为Following。2、Discovery 发现阶段，用于在从节点中发现最新的ZXID和事务日志。或许有人会问：既然Leader被选为主节点，已经是集群里数据最新的了，为什么还要从节点中寻找最新事务呢？ 这是为了防止某些意外情况，比如因网络原因在上一阶段产生多个Leader的情况。 所以这一阶段，Leader集思广益，接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值加1，生成新的epoch分发给各个Follower。 各个Follower收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。3. Synchronization 同步阶段，把Leader刚才收集得到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式的Leader。 自此，故障恢复正式完成。Broadcast:  什么是Broadcast呢？简单来说，就是Zookeeper常规情况下更新数据的时候，由Leader广播到所有的Follower。其过程如下： 1. 客户端发出写入数据请求给任意Follower。 2. Follower把写入数据请求转发给Leader。 3. Leader采用二阶段提交方式，先发送Propose广播给Follower。 4. Follower接到Propose消息，写入日志成功后，返回ACK消息给Leader。 5. Leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower。Zab协议既不是强一致性，也不是弱一致性，而是处于两者之间的单调一致性。它依靠事务ID和版本号，保证了数据的更新和读取是有序的。 Zookeeper的应用:  1. 分布式锁：这是雅虎研究员设计Zookeeper的初衷。利用Zookeeper的临时顺序节点，可以轻松实现分布式锁。 2. 服务注册和发现：利用Znode和Watcher，可以实现分布式服务的注册和发现。最著名的应用就是阿里的分布式RPC框架Dubbo。 3. 共享配置和状态信息：Redis的分布式解决方案Codis，就利用了Zookeeper来存放数据路由表和 codis-proxy 节点的元信息。同时 codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy。 此外，Kafka、HBase、Hadoop，也都依靠Zookeeper同步节点信息，实现高可用。什么是分布式锁: http://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653194065&amp;idx=1&amp;sn=1baa162e40d48ce9b44ea5c4b2c71ad7&amp;chksm=8c99f58bbbee7c9d5b5725da5ee38fe0f89d7a816f3414806785aea0fe5ae766769600d3e982&amp;scene=21#wechat_redirect  Redis分布式锁：set keyname val ex 5 nx，当keyname不存在时，设置key，过期时间是5秒如何用Zookeeper实现分布式锁: http://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653194140&amp;idx=1&amp;sn=07b65a50798c26ecdc0fc555128ab937&amp;chksm=8c99f546bbee7c50b1642dc971cb1f5e244dce661546e141734797c8c23c6c3ad779dfb57d3b&amp;scene=21#wechat_redirect Znode分为四种类型：:  1. 持久节点 （PERSISTENT）：默认的节点类型。创建节点的客户端与zookeeper断开连接后，该节点依旧存在 。 2. 持久节点顺序节点（PERSISTENT_SEQUENTIAL）：所谓顺序节点，就是在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号 3. 临时节点（EPHEMERAL）：和持久节点相反，当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。 4. 临时顺序节点（EPHEMERAL_SEQUENTIAL）：临时顺序节点结合和临时节点和顺序节点的特点：在创建节点时，Zookeeper根据创建的时间顺序给该节点名称进行编号；当创建节点的客户端与zookeeper断开连接后，临时节点会被删除。Zookeeper分布式锁的原理: Zookeeper分布式锁恰恰应用了临时顺序节点。具体如何实现呢？让我们来看一看详细步骤： 获取锁: 首先，在Zookeeper当中创建一个持久节点ParentLock。当第一个客户端想要获得锁时，需要在ParentLock这个节点下面创建一个临时顺序节点 Lock1。之后，Client1查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock1是不是顺序最靠前的一个。如果是第一个节点，则成功获得锁。这时候，如果再有一个客户端 Client2 前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock2。Client2查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock2是不是顺序最靠前的一个，结果发现节点Lock2并不是最小的。于是，Client2向排序仅比它靠前的节点Lock1注册Watcher，用于监听Lock1节点是否存在。这意味着Client2抢锁失败，进入了等待状态。这时候，如果又有一个客户端Client3前来获取锁，则在ParentLock下载再创建一个临时顺序节点Lock3。Client3查找ParentLock下面所有的临时顺序节点并排序，判断自己所创建的节点Lock3是不是顺序最靠前的一个，结果同样发现节点Lock3并不是最小的。于是，Client3向排序仅比它靠前的节点Lock2注册Watcher，用于监听Lock2节点是否存在。这意味着Client3同样抢锁失败，进入了等待状态。这样一来，Client1得到了锁，Client2监听了Lock1，Client3监听了Lock2。这恰恰形成了一个等待队列，很像是Java当中ReentrantLock所依赖的AQS（AbstractQueuedSynchronizer）。 释放锁: 释放锁分为两种情况：1. 任务完成，客户端显示释放当任务完成时，Client1会显示调用删除节点Lock1的指令。2. 任务执行过程中，客户端崩溃获得锁的Client1在任务执行过程中，如果Duang的一声崩溃，则会断开与Zookeeper服务端的链接。根据临时节点的特性，相关联的节点Lock1会随之自动删除。由于Client2一直监听着Lock1的存在状态，当Lock1节点被删除，Client2会立刻收到通知。这时候Client2会再次查询ParentLock下面的所有节点，确认自己创建的节点Lock2是不是目前最小的节点。如果是最小，则Client2顺理成章获得了锁。同理，如果Client2也因为任务完成或者节点崩溃而删除了节点Lock2，那么Client3就会接到通知。最终，Client3成功得到了锁。 Zookeeper如何保证数据一致性: https://juejin. im/post/6844904163042656263 "
    }, {
    "id": 10,
    "url": "/Kafka/",
    "title": "Kafka",
    "body": "2021/02/09 - Kafka:    https://www. jianshu. com/p/5f510cb9d7f1     https://snailclimb. gitee. io/javaguide/#/docs/system-design/distributed-system/message-queue/Kafka%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%80%BB%E7%BB%93  "
    }, {
    "id": 11,
    "url": "/C++/",
    "title": "C++",
    "body": "2021/02/09 - 1、C++语法基础: 指针和引用:  指针有自己的一块内存空间，引用只是一个别名。 sizeof 指针大小为4，sizeof 引用为被引用对象的大小。 引用必须初始化，且是一个已存在对象的引用。指针可以初始化为 nullptr。 可以有const指针，但是没有const引用。程序编译过程:  预处理阶段：对源代码文件中文件包含关系（头文件）、预编译语句（宏定义）进行分析和替换，生成预编译文件。 编译阶段：将经过预处理后的预编译文件转换成特定汇编代码，生成汇编文件。 汇编阶段：将编译阶段生成的汇编文件转化成机器码，生成可重定位目标文件。 链接阶段：将多个目标文件及所需要的库连接成最终的可执行目标文件。static、const、#define的用法和区别: stacic:  全局静态变量、局部静态变量，位于静态存储区。 静态函数，只能在当前. cpp或. c文件访问到 类的静态成员：多个对象之间的数据共享，在类的源文件中初始化：int ClassName::paramName = 0; 类的静态函数：不能直接引用类中声明的非静态成员，只能引用类中声明的静态成员。可通过如下方式调用：ClassName::FuncName();const:  修饰变量，说明变量不可被改变。 修饰指针，分为指向常量的指针和指针常量     指针常量：int const *p，p 是一个指针，指向常量 const int   常量指针：int* const p，p 是一个常量指针，指向 int    形参加 const，既避免了拷贝，又避免了函数对值的修改。 修饰成员函数，说明该成员函数内不能修改成员变量。#define和const:  const 常量有数据类型，而宏常量没有，编译器可以对const常量进行类型安全检查，而后者只进行字符替换没有安全检查 const 常量存在于程序的数据段，#define 常量存在于程序的代码段 define 在预处理阶段进行替换，const 在编译时确定其值C 和 C++ 区别:  设计思想上：     C++是面向对象的语言，而C是面向过程的结构化编程语言    语法上：     C++具有封装、继承和多态三种特性   C++相比C，增加多许多类型安全的功能，比如强制类型转换、   C++支持范式编程，比如模板类、函数模板等   C++对象内存模型: 虚函数表 内存中的栈和堆分配:  在C++中，虚拟内存分为代码段、数据段、BSS段、堆区、文件映射区以及栈区六部分。     代码段：包括只读存储区和文本区，其中只读存储区存储字符串常量，文本区存储程序的机器代码。   数据段：存储程序中已初始化的全局变量和静态变量   bss 段：存储未初始化的全局变量和静态变量（局部+全局），以及所有被初始化为0的全局变量和静态变量。   堆区：调用new/malloc函数时在堆区动态分配内存，同时需要调用delete/free来手动释放申请的内存。   映射区：存储动态链接库以及调用mmap函数进行的文件映射   栈：使用栈空间存储函数的返回地址、参数、局部变量、返回值   限制对象堆上或栈上创建: 1. 堆上创建： 析构函数private/protected2. 栈上创建： operator new / operator new [] 私有或protected 2、面对对象基础: 面向对象理解: 析构函数、构造函数、拷贝构造: 虚函数、多态:  多态的实现主要分为静态多态和动态多态，静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定。举个例子：一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数，在父类中声明为加了virtual关键字的函数，在子类中重写时候不需要加virtual也是虚函数。 虚函数的实现：在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(. text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。纯虚函数和虚函数:  C++中虚函数、虚继承内存模型 静态多态是通过函数重载实现的；动态多态是通过虚函数实现的 构造函数不能是虚函数（因为在调用构造函数时，虚表指针并没有在对象的内存空间中，必须要构造函数调用完成后才会形成虚表指针） 纯虚函数是一种特殊的虚函数，在基类中不能对虚函数给出有意义的实现，而把它声明为纯虚函数，它的实现留给该基类的派生类去做。 虚函数在子类里面也可以不重载的；但纯虚函数必须在子类去实现。 带纯虚函数的类叫抽象类，这种类不能直接生成对象，而只有被继承，并重写其虚函数后，才能使用 将可能会被继承的父类的析构函数设置为虚函数，可以保证当我们new一个子类，然后使用基类指针指向该子类对象，释放基类指针时可以释放掉子类的空间，防止内存泄漏。 C++默认的析构函数不是虚函数是因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。而对于不会被继承的类来说，其析构函数如果是虚函数，就会浪费内存。因此C++默认的析构函数不是虚函数，而是只有当需要当作父类时，设置为虚函数。虚函数实现机制:  子类若重写父类虚函数，虚函数表中，该函数的地址会被替换，对于存在虚函数的类的对象，在VS中，对象的对象模型的头部存放指向虚函数表的指针，通过该机制实现多态。虚函数表: 访问限定符 public、private、protected: 继承原理、虚继承、菱形继承: https://blog. 51cto. com/zimomo/1784074  菱形继承：D继承B、C，B和C继承A，A有函数Func，D调用Func时调用不明确， 一种解决方法是使用域限定：d. A::Func()，d. B::Func().  另一种解决方法是虚继承，B和C虚继承A静态绑定和动态绑定:  静态绑定：模板函数 动态绑定：虚函数、多态 静态函数在编译的时候就已经确定运行时机，虚函数在运行的时候动态绑定。虚函数因为用了虚函数表机制，调用的时候会增加一次内存开销new/delete和malloc/free: new/delete是C++的关键字，而malloc/free是C语言的库函数，后者使用必须指明申请内存空间的大小，对于类类型的对象，后者不会调用构造函数和析构函数 重载、重写和隐藏:  重载：两个函数名相同，但是参数列表不同（个数，类型），返回值类型没有要求，在同一作用域中 重写：子类继承了父类，父类中的函数是虚函数，在子类中重新定义了这个虚函数，这种情况是重写 隐藏：不同作用域中，定义的同名函数构成隐藏（不要求函数返回值和函数参数类型相同）。（派生类中与基类同返回值类型、同名和同参数的非虚函数也构成隐藏。）3、语法进阶: 常用的设计模式: 线程安全的单例模式: 内存溢出和内存泄漏: C++11新特性汇总: https://www. lanqiao. cn/courses/605  基于范围的 for 循环 auto，需要先初始化 nullptr：nullptr 的类型为 nullptr_t。nullptr 出现的目的是为了替代 NULL。对于这两个函数来说，如果 NULL 又被定义为了 0， 那么 foo(NULL); 这个语句将会去调用 foo(int)，从而导致代码违反直观。  12 void foo(char *); void foo(int);    lambda 表达式：  123[捕获列表](参数列表) mutable(可选) 异常属性 -&gt; 返回类型 { // 函数体}    右值引用、std::move 方法来将左值转换为右值、右值引用，移动语义，完美转发     move 实际上并不能移动任何东西，他唯一的功能是将一个左值强制转换为一个右值引用，使我们可以通过右值引用使用该值；    初始化列表：POD （plain old data，没有构造、析构和虚函数的类或结构体）类型都可以使用 {} 进行初始化 std::function、std::bind/std::placeholder unordered_map、unordered_set、tuple     unordered_map 内部实现了哈希表，因此其查找速度非常的快   map 内部实现了一个红黑树，有序性，这是map结构最大的优点    智能指针：std::shared_ptr、std::unique_ptr、std::weak_ptr     std::shared_ptr 是一种智能指针，它能够记录多少个 shared_ptr 共同指向一个对象，从而消除显示的调用 delete，当引用计数变为零的时候就会将对象自动删除   std::unique_ptr 是一种独占的智能指针，它禁止其他智能指针与其共享同一个对象，从而保证了代码的安全   std::weak_ptr 是一种弱引用（相比较而言 std::shared_ptr 就是一种强引用）。弱引用不会引起引用计数增加。为了解决shared_ptr相互引用导致的内存泄漏。    正则表达式库 语言级线程支持，std::thread, std::mutex, std::future静态链接库和动态链接库: 静态链接:  函数和数据被编译进一个二进制文件。在使用静态库的情况下，在编译链接可执行文件时，链接器从库中复制这些函数和数据并把它们和应用程序的其它模块组合起来创建最终的可执行文件。 空间浪费：因为每个可执行程序中对所有需要的目标文件都要有一份副本，所以如果多个程序对同一个目标文件都有依赖，会出现同一个目标文件都在内存存在多个副本； 更新困难：每当库函数的代码修改了，这个时候就需要重新进行编译链接形成可执行程序。 运行速度快：但是静态链接的优点就是，在可执行程序中已经具备了所有执行程序所需要的任何东西，在执行的时候运行速度快。动态链接:  动态链接的基本思想是把程序按照模块拆分成各个相对独立部分，在程序运行时才将它们链接在一起形成一个完整的程序，而不是像静态链接一样把所有程序模块都链接成一个单独的可执行文件。 共享库：就是即使需要每个程序都依赖同一个库，但是该库不会像静态链接那样在内存中存在多份副本，而是这多个程序在执行时共享同一份副本； 更新方便：更新时只需要替换原来的目标文件，而无需将所有的程序再重新链接一遍。当程序下一次运行时，新版本的目标文件会被自动加载到内存并且链接起来，程序就完成了升级的目标。 性能损耗：因为把链接推迟到了程序运行时，所以每次执行程序都需要进行链接，所以性能会有一定损失。强制类型转换:  const_cast：去const，用于将const变量转为非const static_cast：     用于非多态类型的转换   不执行运行时类型检查（转换安全性不如 dynamic_cast）   通常用于转换数值数据类型（如 float -&gt; int）    dynamic_cast     用于多态类型的转换   执行运行时类型检查   只适用于指针或引用   可以在整个类层次结构中移动指针，包括向上转换、向下转换    reinterpret_castmalloc内存分配原理: https://blog. csdn. net/wz1226864411/article/details/77934941  malloc基本的实现原理就是维护一个内存空闲链表，当申请内存空间时，搜索内存空闲链表，找到适配的空闲内存空间，然后将空间分割成两个内存块，一个变成分配块，一个变成新的空闲块。如果没有搜索到，那么就会用sbrk()才推进brk指针来申请内存空间。 搜索空闲块最常见的算法有：首次适配，下一次适配，最佳适配。     首次适配：第一次找到足够大的内存块就分配，这种方法会产生很多的内存碎片。   下一次适配：也就是说等第二次找到足够大的内存块就分配，这样会产生比较少的内存碎片。   最佳适配：对堆进行彻底的搜索，从头开始，遍历所有块，使用数据区大小大于size且差值最小的块作为此次分配的块。   合并空闲块: 在释放内存块后，如果不进行合并，那么相邻的空闲内存块还是相当于两个内存块，会形成一种假碎片。所以当释放内存后，我们需要将两个相邻的内存块进行合并。 "
    }, {
    "id": 12,
    "url": "/ComputerNetwork/",
    "title": "计算机网络",
    "body": "2021/02/06 - TCP报文格式 1、OSI七层模型、TCP/IP四层:       OSI七层模型   TCP/IP模型   功能   TCP/IP协议族         应用层   应用层   文件传输，电子邮件，文件服务，虚拟终端   TFTP,HTTP:80,SNMP,FTP:21,SMTP:25,DNS:53,Telnet       表示层       数据格式化，代码转换，数据加密   没有协议       会话层       接触或建立别的节点的联系   没有协议       传输层   传输层   提供端对端的接口   TCP,UDP       网络层   网络层   为数据选择路由   IP,ICMP,RIP,OSPF,BGP,IGMP       数据链路层   链路层   传输有地址的帧以及错误检测功能   SLIP,CSLIP,PPP,ARP,RARP,MTU       物理层       以二进制数据形式在物理媒体上传输数据   ISO2110,IEEE802,IEEE802. 2   什么是四层模型  第一层：应用层，主要有负责web浏览器的HTTP协议， 文件传输的FTP协议，负责电子邮件的SMTP协议，负责域名系统的DNS等。 第二层：传输层，主要是有可靠传输的TCP协议，特别高效的UDP协议。主要负责传输应用层的数据包。 第三层：网络层，主要是IP协议。主要负责寻址（找到目标设备的位置） 第四层：数据链路层，主要是负责转换数字信号和物理二进制信号。2、TCP和UDP区别: | | UDP | TCP ||—|—|—|| 是否连接 | 无连接 | 面向连接 || 是否可靠 | 不可靠传输，不使用流量控制和拥塞控制 | 可靠传输，使用流量控制和拥塞控制 || 连接对象个数 | 支持一对一，一对多，多对一和多对多交互通信 | 只能是一对一通信 || 传输方式 | 面向报文 | 面向字节流 || 首部开销 | 首部开销小，仅8字节 | 首部最小20字节，最大60字节 || 适用场景 | 适用于实时应用（IP电话、视频会议、直播等） | 适用于要求可靠传输的应用，例如文件传输 | 3、TCP协议3次握手、4次挥手: TCP协议3次握手 三次握手最主要的目的就是双方确认自己与对方的发送与接收是正常的 3. 1、TCP连接建立需要为什么不是两次握手:  为什么A还要发送一次确认呢？这主要是为了防止已失效的连接请求报文段突然又传送到了B，因而产生错误。 所谓“已失效的连接请求报文段”是这样产生的。考虑一种正常情况。A发出连接请求，但因连接请求报文丢失而未收到确认。于是A再重传一次连接请求。后来收到了确认，建立了连接。数据传输完毕后，就释放了连接。A共发送了两个连接请求报文段，其中第一个丢失，第二个到达了B。没有“已失效的连接请求报文段”。 现假定出现一种异常情况，即A发出的第一个连接请求报文段并没有丢失，而是在某些网络结点长时间滞留了，以致延误到连接释放以后的某个时间才到达B。本来这是一个早已失效的报文段。但B收到此失效的连接请求报文段后，就误认为是A又发出一次新的连接请求。于是就向A发出确认报文段，同意建立连接。假定不采用三次握手，那么只要B发出确认，新的连接就建立了。 由于现在A并没有发出建立连接的请求，因此不会理睬B的确认，也不会向B发送数据。但B却以为新的运输连接已经建立了，并一直等待A发来数据。B的许多资源就这样白白浪费了。 采用三次握手的办法可以防止上述现象的发生。例如在刚才的情况下，A不会向B的确认发出确认。B由于收不到确认，就知道A并没有要求建立连接。3. 2、TCP第三次握手失败会出现什么:  失败时会超时重传SYN+ACK，重传次数根据 /proc/sys/net/ipv4/tcp_synack_retries 来指定，默认是5次。如果重传指定次数到了后，仍然未收到ACK应答，会给客户端发RST报文，进入CLOSED状态，这个时候客户端应该也会关闭连接。3. 3、TCP四次挥手: TCP协议4次挥手  CLOSE-WAIT 状态问题：客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送FIN 连接释放报文。 A收到B的FIN报文后，后进入到TIME-WAIT（时间等待）状态。请注意，现在TCP连接还没有释放掉。必须经过时间等待计时器(TIME-WAIT timer)设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做最长报文段寿命(Maximum Segment Lifetime)，RFC 793建议设为2分钟。但这完全是从工程上来考虑，对于现在的网络，MSL = 2分钟可能太长了一些。因此TCP允许不同的实现可根据具体情况使用更小的MSL值。因此，从A进入到TIME-WAIT状态后，要经过4分钟才能进入到CLOSED状态，才能开始建立下一个新的连接。当A撤销相应的传输控制块TCB后，就结束了这次的TCP连接。12345678910111213TIME_WAIT调优#表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭net. ipv4. tcp_syncookies = 1#表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭net. ipv4. tcp_tw_reuse = 1#表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭net. ipv4. tcp_tw_recycle = 1#表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间net. ipv4. tcp_fin_timeout=30TIME_WAIT：表示主动关闭，通过优化系统内核参数可容易解决。CLOSE_WAIT：表示被动关闭，需要从程序本身出发。ESTABLISHED：表示正在通信 **为什么A在TIME-WAIT状态必须等待2MSL的时间呢？这有两个理由。** 第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN + ACK报文段的确认。B会超时重传这个FIN + ACK报文段，而A就能在2MSL时间内收到这个重传的FIN + ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后，A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN + ACK报文段，因而也不会再发送一次确认报文段。这样，B就无法按照正常步骤进入CLOSED状态。 第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。 B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。我们注意到，B结束TCP连接的时间要比A早一些。3. 4、2MSL(Maximum Segment Lifetime)意义:  1、保证最后一次ACK报文能到服务端，能进行超时重传。 2、2MSL后，这次连接的所有报文都会消失，不会影响下一次连接。4、TCP长连接和短链接及优缺点:  所谓长连接，指在一个TCP连接上可以连续发送多个数据包，在TCP连接保持期间，如果没有数据包发送，需要双方发检测包以维持此连接，一般需要自己做在线维持（不发生RST包和四次挥手）。 短连接是指通信双方有数据交互时，就建立一个TCP连接，数据发送完成后，则断开此TCP连接（管理起来比较简单，存在的连接都是有用的连接，不需要额外的控制手段）； tcp长连接优缺点：长连接可以省去较多的tcp建立/关闭的操作，减少浪费，节省时间，对于频繁请求资源的客户，较适用于长连接；client和server如果长时间不关闭的话，会存在一个问题，随着客户的越来越多，server早晚会有扛不住的一天，这时需要采取一些策略，如关闭一些长时间不读写操作的连接，这样可以避免一些恶意连接导致server端服务受损，如果条件再允许，就可以以客户端为颗粒度，限制每个客户端的最大连接数 tcp短连接优缺点：短连接对于服务器来说较为简单，存在的连接都是有用的连接，不需要额外的控制，但如果客户端连接频繁，会在tcp的建立和关闭上浪费时间。5、TCP如何保证可靠性: https://juejin. im/post/6861491957534261255 5. 1、差错控制:  差错控制的方法有：校验和、确认应答、重传 三种 TCP 通过首部中的校验和字段，判断数据是否损坏，如果损坏，则直接丢弃。 在 TCP 中，发送端的数据到达接收端时，接收端会返回一个“我收到消息了”的通知，这个通知就是确认应答（ACK, Acknowledge character）。 TCP共实现了两种重传机制：超时重传和快重传5. 1. 1、超时重传:  当发送端发送数据后，如果在特定时间间隔内还没有收到 ACK，就会进行超时重传。特定时间：RTT + 偏差值，Round Trip Time 报文段的往返时间，如果网络稳定性较差，那么相应的偏差值也会较大，相反的，若网络比较稳定，则偏差值也会较小。 由于最初的数据包还不知道其 RTT，所以其超时重传时间一般设置为 6秒。5. 1. 2、快重传:  快重传基于窗口控制（后面会讲到），是指发送端在连续三次收到同一个确认应答后，就会将其对应的数据进行重发，这种机制比超时重传更加高效。5. 2、流量控制:  所谓流量控制(flow control)就是让发送方的发送速率不要太快，要让接收方来得及接收。 TCP 以一个段为单位，每发送一个段就要进行一次确认应答（ACK）处理，这样传输的方式有一个缺点，就是包的往返时间越长，效率就越低。 所以 TCP 引入了 窗口 这个概念，在窗口范围内，即使没有收到 ACK，也可以继续发送数据，无需一直等待 ACK，这个机制的实现使用了大量的缓冲区。 通过流量控制，发送端需要根据接收端的实际接收能力控制发送的数据量。 利用滑动窗口实现流量控制，滑动窗口以字节为单位。 TCP 首部中带有窗口大小字段，在返回 ACK 时，就会带上这个字段，接收端接收到了这个字段后，就对会自己的窗口大小进行更新（滑动）滑动窗口 滑动窗口发送 5. 3、拥塞控制: 慢开始与拥塞避免算法拥塞窗口大小  拥塞是由于网络中的路由器由于超载而引起的严重延迟现象，拥塞的发生会造成数据丢失，进而引发超时重传，而超时重传又会进一步加剧拥塞，如果不进行控制，最终会导致整个网络的瘫痪。 拥塞控制主要通过利用发送窗口限制数据流的速度，减缓注入网络的数据流量后，拥塞自然就会解除。 而起关键作用的发送窗口的大小，取决于两个因素，一个是接收窗口的大小，另一个就是拥塞窗口。 慢启动：定义拥塞窗口，一开始将该窗口大小设为1MSS（1460字节），之后每次收到确认应答（经过一个rtt），将拥塞窗口大小*2 拥塞避免：设置慢启动阈值（ssthresh），一般开始都设为65535字节。拥塞避免是指当拥塞窗口大小达到这个阈值，拥塞窗口的值不再指数上升，而是加法增加（每次确认应答/每个rtt，拥塞窗口大小+1MSS），以此来避免拥塞。 拥塞检测：超时重传或连续收到三个相同的 ACK，则认为发生拥塞。     一旦发生超时重传，我们需要先将慢启动阈值设为当前窗口大小的一半，并且将拥塞窗口大小设置为1MSS，然后重新进入慢启动阶段。   如果连续收到了三个相同的 ACK，将慢启动阀值设为当前窗口的一半，拥塞窗口设置为慢启动阀值+3。   6、TCP如何解决粘包、拆包问题:  消息数据定长，比如定长100字节 消息数据使用特定分割符区分界限，比如使用换号符号做分割 把消息数据分成消息头和消息体，消息头带消息的长度，接收方收到后根据消息头中的长度解析数据。7、UDP如何实现TCP可靠传输:  1、添加seq/ack机制，确保数据发送到对端 2、添加发送和接收缓冲区，主要是用户超时重传。 3、添加超时重传机制。8、ARP: ARP解析过程:  ARP地址解析协议，将IP地址解析为MAC地址。 主机发送信息时将包含目标IP地址的ARP请求广播到网络上的所有主机，并接收返回消息，以此确定目标的物理地址；收到返回消息后将该IP地址和物理地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。 为了确定目标的MAC地址，首先查找ARP缓存表。如果要查找的MAC地址不在表中，ARP会发送一个广播，从而发现目的地的MAC地址，并记录到ARP缓存表中以便下次查找。ARP协议:  将ip地址解析到mac地址。 目标IP与自己在同一网段：     arp高速缓存有目标IP的MAC地址：直接发送到该物理地址   arp高速缓存没有目标IP的MAC地址：发送ARP广播请求目标IP的MAC地址，缓存该MAC地址，然后发数据报到该MAC地址。    目标IP与自己不在同一个网段：这种情况需要将包发给默认网关，所以主要获取网关的MAC地址     arp高速缓存有默认网关的MAC地址：直接发送IP数据报道默认网关，再由网关转发到外网。   arp高速缓存没有默认网关的MAC地址 ：还是发送ARP广播请求默认网关的MAC地址，缓存该地址，并且发送数据报到网关。   9、DNS原理: 9. 1、DNS解析过程: (https://www. jianshu. com/p/189311c71b0e)  浏览器缓存：查看浏览器缓存的域名与IP的映射关系，如果有则解析成功。 主机缓存：浏览器缓存没命中，查询主机DNS缓存。 LDNS（本地域名服务器）：本机缓存没命中，则查找本地域名服务器。 Root Server：LDNS没有查到，就会发送请求到Root Server。Root Server不直接解析域名，它会返回所查询域的gTLD地址。 gTLD服务器：gTLD为国际顶级域名服务器，如 . com，. cn，. org都由它管理。LDNS发送请求到gTLD，gTLD返回对应域名的Name Server服务器地址。 Name Server（域名服务器）：Name Server为域名提供商的域名解析服务器。域名最终在这里解析，上述步骤要么是缓存，要么是提供域名解析服务器地址。想想也挺合理，在哪买的域名就在哪绑定IP。 DNS劫持：在DNS服务器中，将 www. xxx. com 的域名对应的IP地址进行了变化。你解析出来的 域名对应的IP，在劫持前后不一样。 DNS劫持：域名劫持是互联网攻击的一种方式，通过攻击域名解析服务器（DNS），或伪造域名解析服务器（DNS）的方法，把目标网站域名解析到错误的IP地址从而实现用户无法访问目标网站的目的或者蓄意或恶意要求用户访问指定IP地址（网站）的目的。9. 2、DNS使用TCP还是UDP:  DNS在区域传输的时候使用TCP协议,其他时候使用UDP协议。 DNS同时占用TCP和UDP的53号端口。 因为查询很频繁，使用UDP报文给服务器带来的负担小，所以查询的时候使用的是UDP报文。 主副DNS进行区域传送的时候，用TCP，因为要保证数据的准确性。 DNS区域传输的时候使用TCP协议：     1. 辅域名服务器会定时（一般3小时）向主域名服务器进行查询以便了解数据是否有变动。如有变动，会执行一次区域传送，进行数据同步。区域传送使用TCP而不是UDP，因为数据同步传送的数据量比一个请求应答的数据量要多得多。   2. TCP是一种可靠连接，保证了数据的准确性。    域名解析时使用UDP协议：     客户端向DNS服务器查询域名，一般返回的内容都不超过512字节，用UDP传输即可。不用经过三次握手，这样DNS服务器负载更低，响应更快。理论上说，客户端也可以指定向DNS服务器查询时用TCP，但事实上，很多DNS服务器进行配置的时候，仅支持UDP查询包。   10、HTTP常见问题: (https://mp. weixin. qq. com/s/amOya0M00LwpL5kCS96Y6w)  HTTP 是超文本传输协议，也就是HyperText Transfer Protocol HTTP 常见的状态码，有哪些？     1xx 类状态码属于提示信息   2xx 类状态码表示服务器成功处理了客户端的请求。200 OK   3xx 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。301 Moved Permanently   4xx 类状态码表示客户端发送的报文有误。400 Bad Request、403 Forbidden、404 Not Found   5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。500 Internal Server Error、501 Not Implemented、502 Bad Gateway、503 Service Unavailable    HTTP 常见字段有：Host、Content-Length、Connection、Content-Type、Content-Encoding、 GET 和 POST 的区别？     Get 方法的含义是请求从服务器获取资源，这个资源可以是静态的文本、页面、图片视频等。   POST 向 URI 指定的资源提交数据，数据就放在报文的 body 里。   GET 方法就是安全且幂等，POST是不安全的，不是幂等的    HTTP 最突出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」，缺点是无状态、明文传输、不安全（通信使用明文（不加密），内容可能会被窃听；不验证通信方的身份，因此有可能遭遇伪装；无法证明报文的完整性，所以有可能已遭篡改）。 HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致 HTTP/1. 1 提出了长连接的通信方式，减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。 HTTP/1. 1 相比 HTTP/1. 0 性能上的改进：     使用 TCP 长连接的方式改善了 HTTP/1. 0 短连接造成的性能开销。   支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。    12345POST /index. html HTTP/1. 1HOST: www. XXX. comUser-Agent: Mozilla/5. 0(Windows NT 6. 1;rv:15. 0) Firefox/15. 0Username=admin&amp;password=admin 1234567891011121314HTTP/1. 1 200 OKContent-Encoding: gzipContent-Type: text/html;charset=utf-8&lt;!DOCTYPE html&gt;&lt;html lang= en &gt;&lt;head&gt;  &lt;meta charset= UTF-8  /&gt;  &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;  &lt;p&gt;this is http response&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; HTTP有两种报文：请求报文和响应报文。     HTTP请求报文主要包括请求行、请求头部以及请求的数据（实体）三部分         请求行（HTTP请求报文的第一行）：请求行由方法字段、URL字段和HTTP协议版本字段。其中，方法字段严格区分大小写，当前HTTP协议中的方法都是大写，方法字段如下介绍如下：     请求头部：位于请求行的下面, 是一个个的key-value值     空行(CR+LF)：请求报文用空行表示header和请求数据的分隔     请求数据：GET方法没有携带数据， POST方法会携带一个body          HTTP的响应报文包括：状态行，响应头部，相应的数据(响应体)         状态行包括：HTTP版本号，状态码和状态值组成。     响应头类似请求头，是一系列key-value值     空白行：同上，响应报文也用空白行来分隔header和数据     响应体：响应的数据          11、什么是 HTTPS 协议:  https://segmentfault. com/a/1190000012196642 http://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653197101&amp;idx=1&amp;sn=d1fe482561d3d079363032ec182c5b3b&amp;chksm=8c99e1f7bbee68e10f8470453637a7d434751a9414ceeffbbb9601f5ae2ba64e26fa6a88a99b&amp;scene=21#wechat_redirect SSL（Secure Socket Layer，安全套接字层） TLS（Transport Layer Security，传输层安全）对称加密算法和非对称加密算法:  HTTPS在加密过程中使用了非对称加密技术和对称加密技术。 对称加密算法：又称共享密钥加密算法，指加密和解密使用相同密钥的加密算法。对称加密算法用来对敏感数据等信息进行加密，常用的算法包括DES、3DES、AES、DESX、Blowfish、RC4、RC5、RC6。 非对称加密算法：指加密和解密使用不同密钥的加密算法，也称为公私钥加密/公开密钥加密算法。假设两个用户要加密交换数据，双方交换公钥，使用时一方用对方的公钥加密，另一方即可用自己的私钥解密。常见的非对称加密算法：RSA、DSA（数字签名用）、ECC（移动设备用）、Diffie-Hellman、El Gamal。     当客户端第一次发请求和服务器协商的时候，服务器就生成了一对公钥和私钥。   紧接着，服务器把公钥发给客户端（明文，不需要做任何加密），客户端接收后，随机生成一个密钥，使用服务器发过来的公钥进行加密。   再接着，客户端把使用公钥加密的密钥发给服务器，服务器接收到了以后，用配对的私钥进行解密，就得到了客户端随机生成的那个密钥。   这个时候，客户端和服务端所持的密钥都是相同的。此时，交换密钥环节就完成了。   于是通信开始时就可进行共享密钥加密方式来进行加密。    HTTPS采用共享密钥加密和公开密钥加密两者并用的混合加密机制。在交换密钥使用环节使用公开密钥加密方式，之后建立的通信交换报文阶段则使用共享密钥加密方式。 如何保证服务器传过来的公开密钥的正确性。换句话说，就是保证它不被拦截篡改。     使用证书保证公钥的正确性   首先，服务器的运营人员向数字证书机构提出公开密钥的申请。数字证书认证机构在判明提出申请者的身份之后，会对已申请的公开密钥做数字签名，然后分配这个已签名的公开密钥，并将该公开密钥放入公钥证书后绑定在一起。   接下来，服务器会把这份由数字证书认证机构颁发的公钥证书发给客户端。这个时候，客户端可以使用数字证书机构的公开密钥对其进行验证。一旦验证成功，客户端便能够确定这个公开密钥是可信的。   CA除了给申请者发布证书，它自己本身也有自己的证书。CA自身的数字证书（一般由它自己生成）在我们操作系统刚安装好的时候，这些CA自身的数字证书就已经被微软（或者其它操作系统的开发机构）安装在操作系统中了。而CA的公钥就包含在其中。这样，CA就可以通过自身的私钥对发布的数字证书进行签名，而在客户端就能够用对应的公钥来对其进行解密。   12、HTTP和HTTPS区别: 12. 1、HTTP和HTTPS区别：:  1）HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。 2）HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。 3）HTTP 的端口号是 80，HTTPS 的端口号是 443。 4）HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。12. 2、HTTPS优点：:  HTTPS传输数据过程中使用密钥进行加密，所以安全性更高。（HTTPS 采用的加密方式: HTTPS 采用混合的加密机制。所有传输的内容都经过加密，加密采用对称加密，但对称加密的密钥用服务器方的证书进行了非对称加密。） HTTPS协议可以认证用户和服务器，确保数据发送到正确的用户和服务器12. 3、HTTPS缺点：:  HTTPS握手阶段延时较高：由于在进行HTTP会话之前还需要进行SSL握手，因此HTTPS协议握手阶段延时增加 HTTPS部署成本高：一方面HTTPS协议需要使用证书来验证自身的安全性，所以需要购买CA证书；另一方面由于采用HTTPS协议需要进行加解密的计算，占用CPU资源较多，需要的服务器配置或数目高13、HTTP1. 0、HTTP1. 1、HTTP2. 0区别: 13. 1、HTTP1. 0 和 HTTP1. 1 的区别:  长连接(Persistent Connection)：HTTP1. 1支持长连接和请求的流水线处理，在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟，在HTTP1. 1中默认开启长连接keep-alive，一定程度上弥补了HTTP1. 0每次请求都要创建连接的缺点。HTTP1. 0需要使用keep-alive参数来告知服务器端要建立一个长连接。 节约带宽：HTTP1. 0中存在一些浪费带宽的现象，例如客户端只是需要某个对象的一部分，而服务器却将整个对象送过来了，并且不支持断点续传功能。HTTP1. 1支持只发送header信息（不带任何body信息），如果服务器认为客户端有权限请求服务器，则返回100，客户端接收到100才开始把请求body发送到服务器；如果返回401，客户端就可以不用发送请求body了节约了带宽。 HOST域：在HTTP1. 0中认为每台服务器都绑定一个唯一的IP地址，因此，请求消息中的URL并没有传递主机名（hostname），HTTP1. 0没有host域。随着虚拟主机技术的发展，在一台物理服务器上可以存在多个虚拟主机（Multi-homed Web Servers），并且它们共享一个IP地址。HTTP1. 1的请求消息和响应消息都支持host域，且请求消息中如果没有host域会报告一个错误（400 Bad Request）。 缓存处理：在HTTP1. 0中主要使用header里的If-Modified-Since,Expires来做为缓存判断的标准，HTTP1. 1则引入了更多的缓存控制策略例如Entity tag，If-Unmodified-Since, If-Match, If-None-Match等更多可供选择的缓存头来控制缓存策略。 错误通知的管理：在HTTP1. 1中新增了24个错误状态响应码，如409（Conflict）表示请求的资源与资源的当前状态发生冲突；410（Gone）表示服务器上的某个资源被永久性的删除。13. 2、HTTP1. 1和HTTP2. 0的区别:  多路复用：HTTP2. 0使用了多路复用的技术，做到同一个连接并发处理多个请求，而且并发请求的数量比HTTP1. 1大了好几个数量级。HTTP1. 1也可以多建立几个TCP连接，来支持处理更多并发的请求，但是创建TCP连接本身也是有开销的。 头部数据压缩：在HTTP1. 1中，HTTP请求和响应都是由状态行、请求/响应头部、消息主体三部分组成。一般而言，消息主体都会经过gzip压缩，或者本身传输的就是压缩过后的二进制文件，但状态行和头部却没有经过任何压缩，直接以纯文本传输。随着Web功能越来越复杂，每个页面产生的请求数也越来越多，导致消耗在头部的流量越来越多，尤其是每次都要传输UserAgent、Cookie这类不会频繁变动的内容，完全是一种浪费。HTTP1. 1不支持header数据的压缩，HTTP2. 0使用HPACK算法对header的数据进行压缩，这样数据体积小了，在网络上传输就会更快。14、浏览器输入网址: 12345678910111、浏览器查找域名的IP地址 （DNS：获取域名对应的IP）2、浏览器向web服务器发送HTTP请求（cookies会随着请求发送给服务器）3、服务器处理请求 （请求 处理请求 参数、cookies、生成一个HTML响应）4、服务器返回HTTP报文，发回一个HTML响应。5、浏览器解析渲染页面，浏览器开始显示HTML。6、连接结束 - 浏览器要将URL解析为IP地址，解析域名就要用到DNS协议，首先主机会查询DNS的缓存，如果没有就给本地DNS发送查询请求。DNS查询分为两种方式，一种是递归查询，一种是迭代查询。如果是迭代查询，本地的DNS服务器，向根域名服务器发送查询请求，根域名服务器告知该域名的一级域名服务器，然后本地服务器给该一级域名服务器发送查询请求，然后依次类推直到查询到该域名的IP地址。DNS服务器是基于UDP的，因此会用到UDP协议。 - 得到IP地址后，浏览器就要与服务器建立一个http连接。因此要用到http协议，http协议报文格式上面已经提到。http生成一个get请求报文，将该报文传给TCP层处理，所以还会用到TCP协议。如果采用https还会使用https协议先对http数据进行加密。TCP层如果有需要先将HTTP数据包分片，分片依据路径MTU和MSS。TCP的数据包然后会发送给IP层，用到IP协议。IP层通过路由选路，一跳一跳发送到目的地址。当然在一个网段内的寻址是通过以太网协议实现(也可以是其他物理层协议，比如PPP，SLIP)，以太网协议需要直到目的IP地址的物理地址，有需要ARP协议。 其中：- 1、DNS协议，http协议，https协议属于应用层：应用层是体系结构中的最高层。应用层确定进程之间通信的性质以满足用户的需要。这里的进程就是指正在运行的程序。应用层不仅要提供应用进程所需要的信息交换和远地操作，而且还要作为互相作用的应用进程的用户代理，来完成一些为进行语义上有意义的信息交换所必须的功能。应用层直接为用户的应用进程提供服务。- 2、TCP/UDP属于传输层：传输层的任务就是负责主机中两个进程之间的通信。因特网的传输层可使用两种不同协议：即面向连接的传输控制协议TCP，和无连接的用户数据报协议UDP。面向连接的服务能够提供可靠的交付，但无连接服务则不保证提供可靠的交付，它只是“尽最大努力交付”。这两种服务方式都很有用，备有其优缺点。在分组交换网内的各个交换结点机都没有传输层。- 3、IP协议，ARP协议属于网络层：网络层负责为分组交换网上的不同主机提供通信。在发送数据时，网络层将运输层产生的报文段或用户数据报封装成分组或包进行传送。在TCP/IP体系中，分组也叫作IP数据报，或简称为数据报。网络层的另一个任务就是要选择合适的路由，使源主机运输层所传下来的分组能够交付到目的主机。- 4、数据链路层：当发送数据时，数据链路层的任务是将在网络层交下来的IP数据报组装成帧，在两个相邻结点间的链路上传送以帧为单位的数据。每一帧包括数据和必要的控制信息（如同步信息、地址信息、差错控制、以及流量控制信息等）。控制信息使接收端能够知道—个帧从哪个比特开始和到哪个比特结束。控制信息还使接收端能够检测到所收到的帧中有无差错。- 5、物理层：物理层的任务就是透明地传送比特流。在物理层上所传数据的单位是比特。传递信息所利用的一些物理媒体，如双绞线、同轴电缆、光缆等，并不在物理层之内而是在物理层的下面。因此也有人把物理媒体当做第0层。15、广播风暴: 广播风暴也叫网络广播风暴，广播风暴(broadcast storm)故障，即一个数据包或帧被传送到本地网段(由广播域定义)上的每个节点就是广播；网络上的广播帧由于被转发，数量急剧增加而出现正常网络通信的反常现象。广播风暴会占用相当可观的网络带宽，导致正常数据包无法正常运行。当广播数据充斥网络无法处理并占用大量网络带宽，导致正常业务不能运行，这就发生了广播风暴，造成局域网局部或整个网络瘫痪。 "
    }, {
    "id": 13,
    "url": "/Database/",
    "title": "数据库",
    "body": "2021/02/05 - 事务的ACID特性:  事务（Transaction）是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元。事务是DBMS中最基础的单位，事务不可分割。 事务具有4个基本特征，分别是：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Duration），简称ACID。 原子性：事务被视为不可分割的最小单元，事物的所有操作要不成功，要不失败回滚，而回滚可以通过日志来实现，日志记录着事务所执行的修改操作，在回滚时反向执行这些修改操作。（原子性实现原理 - Undo Log） 一致性：数据库在事务执行前后都保持一致性状态，在一致性状态下，所有事务对一个数据的读取结果都是相同的。 隔离性：一个事务所做的修改在最终提交以前，对其他事务是不可见的。（隔离性实现原理 - 锁） 持久性：一旦事务提交，则其所做的修改将会永远保存到数据库中。（持久性实现原理 - Redo Log）隔离级别:  Read Uncommitted（读取未提交）：最低的隔离级别，什么都不需要做，一个事务可以读到另一个事务未提交的结果。所有的并发事务问题都会发生。 Read Committed（读取提交内容）：只有在事务提交后，其更新结果才会被其他事务看见。可以解决脏读问题。 Repeated Read（可重复读）：在一个事务中，对于同一份数据的读取结果总是相同的，无论是否有其他事务对这份数据进行操作，以及这个事务是否提交。可以解决脏读、不可重复读。 Serialization（可串行化）：事务串行化执行，隔离级别最高，牺牲了系统的并发性。可以解决并发事务的所有问题。123脏读：一个事务还未提交，另外一个事务访问此事务修改的数据，并使用，读取了事务中间状态数据。不可重复读：一个事务读取同一条记录2次，得到的结果不一致，由于在2次读取之间另外一个事务对此行数据进行了修改。幻读：一个事务读取2次，得到的记录条数不一致，由于2次读取之间另外一个事务对数据进行了增删。不同事务隔离级别有不同的效果：       隔离级别   脏读   不可重复读   幻读         读未提交   √   √   √       读已提交   ×   √   √       可重复读   ×   ×   √       可串行化   ×   ×   ×   数据库引擎InnoDB、MyISAM:  InnoDB是一个事务型的存储引擎，有行级锁定和外键约束。提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别。 MyISAM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT或UPDATE数据时即写操作需要锁定整个表，效率便会低一些。MyISAM中存储了表的行数。 https://snailclimb. gitee. io/javaguide/#/docs/database/MySQL?id=myisam%e5%92%8cinnodb%e5%8c%ba%e5%88%abMVCC实现原理:  Multi-Version Concurrency Control，即多版本并发控制。 InnoDB 的 MVCC, 是通过在每行记录后面保存两个隐藏的列来实现的, 这两个列，分别保存了这个行的创建时间，一个保存的是行的删除时间。这里存储的并不是实际的时间值, 而是系统版本号 (可以理解为事务的 ID)，每次开始一个新的事务，系统版本号就会自动递增；当删除一条数据的时候，该数据的删除时间列就会存上当前事务的版本号 ；事务开始时刻的系统版本号会作为事务的 ID； https://juejin. cn/post/6844903986143690765 https://segmentfault. com/a/1190000012650596InnoDB存储引擎在数据库每行数据的后面添加了三个字段:                6字节的事务ID(DB_TRX_ID)字段: 用来标识最近一次对本行记录做修改(insert     update)的事务的标识符, 即最后一次修改(insert     update)本行记录的事务id。至于delete操作，在innodb看来也不过是一次update操作，更新行中的一个特殊位将行表示为deleted, 并非真正删除。           7字节的回滚指针(DB_ROLL_PTR)字段: 指写入回滚段(rollback segment)的 undo log record (撤销日志记录记录)。如果一行记录被更新, 则 undo log record 包含 ‘重建该行记录被更新之前内容’ 所必须的信息。 6字节的DB_ROW_ID字段: 包含一个随着新行插入而单调递增的行ID, 当由innodb自动产生聚集索引时，聚集索引会包括这个行ID的值，否则这个行ID不会出现在任何索引中。结合聚簇索引的相关知识点, 我的理解是, 如果我们的表中没有主键或合适的唯一索引, 也就是无法生成聚簇索引的时候, InnoDB会帮我们自动生成聚集索引, 但聚簇索引会使用DB_ROW_ID的值来作为主键; 如果我们有自己的主键或者合适的唯一索引, 那么聚簇索引中也就不会包含 DB_ROW_ID 了案例分析: 小结:  一般我们认为MVCC有下面几个特点：     每行数据都存在一个版本，每次数据更新时都更新该版本   修改时Copy出当前版本, 然后随意修改，各个事务之间无干扰   保存时比较版本号，如果成功(commit)，则覆盖原记录, 失败则放弃copy(rollback)   就是每行都有版本号，保存时根据版本号决定是否成功，听起来含有乐观锁的味道, 因为这看起来正是，在提交的时候才能知道到底能否提交成功    而InnoDB实现MVCC的方式是:     事务以排他锁的形式修改原始数据   把修改前的数据存放于undo log，通过回滚指针与主数据关联   修改成功（commit）啥都不做，失败则恢复undo log中的数据（rollback）   二者最本质的区别是: 当修改数据时是否要排他锁定，如果锁定了还算不算是MVCC？   Innodb的实现真算不上MVCC, 因为并没有实现核心的多版本共存, undo log 中的内容只是串行化的结果, 记录了多个事务的过程, 不属于多版本共存。但理想的MVCC是难以实现的, 当事务仅修改一行记录使用理想的MVCC模式是没有问题的, 可以通过比较版本号进行回滚, 但当事务影响到多行数据时, 理想的MVCC就无能为力了。   比如, 如果事务A执行理想的MVCC, 修改Row1成功, 而修改Row2失败, 此时需要回滚Row1, 但因为Row1没有被锁定, 其数据可能又被事务B所修改, 如果此时回滚Row1的内容，则会破坏事务B的修改结果，导致事务B违反ACID。 这也正是所谓的 第一类更新丢失 的情况。   也正是因为InnoDB使用的MVCC中结合了排他锁, 不是纯的MVCC, 所以第一类更新丢失是不会出现了, 一般说更新丢失都是指第二类丢失更新。   数据库索引及底层实现:  唯一索引：唯一索引是在表上一个或者多个字段组合建立的索引，这个或者这些字段的值组合起来在表中不可以重复 非唯一索引：非唯一索引是在表上一个或者多个字段组合建立的索引，这个或者这些字段的值组合起来在表中可以重复，不要求唯一。 主键索引（主索引）：主键索引（主索引）是唯一索引的特定类型。表中创建主键时自动创建的索引 。一个表只能建立一个主索引。 聚集索引/非聚集索引：聚集索引（聚簇索引），表中记录的物理顺序与键值的索引顺序相同。一个表只能有一个聚集索引。InnoDB 使用 B+ 树，既可以保存实际数据，也可以加速数据搜索，这就是聚簇索引 聚集索引：https://veal98. gitee. io/cs-wiki/#/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%95%B0%E6%8D%AE%E5%BA%93/%E9%9D%A2%E8%AF%95%E6%8C%87%E5%8D%97?id=_6-%e8%81%9a%e9%9b%86%e7%b4%a2%e5%bc%95%e4%b8%8e%e9%9d%9e%e8%81%9a%e9%9b%86%e7%b4%a2%e5%bc%95分布式事务: https://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653193461&amp;idx=1&amp;sn=d69ccec780ae6d3b0c722cf09fa154d1&amp;chksm=8c99f62fbbee7f39cd221bd0ecc9105a5c16e353d82d2407e7f295da9f9172cfd4889d3f12c8&amp;scene=21#wechat_redirect)  分布式事务用于在分布式系统中保证不同节点之间的数据一致性。 分布式事务的实现有很多种，最具有代表性的是由Oracle Tuxedo系统提出的XA分布式事务协议。 XA协议包含两阶段提交（2PC）和三阶段提交（3PC）两种实现，这里我们重点介绍两阶段提交的具体过程。 事务的发起者称协调者，事务的执行者称参与者。 第一阶段：     在XA分布式事务的第一阶段，作为事务协调者的节点会首先向所有的参与者节点发送Prepare请求。   在接到Prepare请求之后，每一个参与者节点会各自执行与事务有关的数据更新，写入Undo Log和Redo Log。如果参与者执行成功，暂时不提交事务，而是向事务协调节点返回“完成”消息。   当事务协调者接到了所有参与者的返回消息，整个分布式事务将会进入第二阶段。    第二阶段：     在XA分布式事务的第二阶段，如果事务协调节点在之前所收到都是正向返回，那么它将会向所有事务参与者发出Commit请求。   接到Commit请求之后，事务参与者节点会各自进行本地的事务提交，并释放锁资源。当本地事务完成提交后，将会向事务协调者返回“完成”消息。   当事务协调者接收到所有事务参与者的“完成”反馈，整个分布式事务完成。    XA两阶段提交的不足：     1. 性能问题：XA协议遵循强一致性。在事务执行过程中，各个节点占用着数据库资源，只有当所有节点准备完毕，事务协调者才会通知提交，参与者提交后释放资源。这样的过程有着非常明显的性能问题。   2. 协调者单点故障问题：事务协调者是整个XA模型的核心，一旦事务协调者节点挂掉，参与者收不到提交或是回滚通知，参与者会一直处于中间状态无法完成事务。   3. 丢失消息导致的不一致问题：在XA协议的第二个阶段，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。    如何避免XA两阶段提交的种种问题呢？有许多其他的分布式事务方案可供选择：     1. XA三阶段提交：XA三阶段提交在两阶段提交的基础上增加了CanCommit阶段，并且引入了超时机制。一旦事物参与者迟迟没有接到协调者的commit请求，会自动进行本地commit。这样有效解决了协调者单点故障的问题。但是性能问题和不一致的问题仍然没有根本解决。CanCommit、PreCommit、DoCommit   2. MQ事务：利用消息中间件来异步完成事务的后一半更新，实现系统的最终一致性。这个方式避免了像XA协议那样的性能问题。   3. TCC事务：TCC事务是Try、Commit、Cancel三种指令的缩写，其逻辑模式类似于XA两阶段提交，但是实现方式是在代码层面来人为实现。   缓存穿透、击穿、雪崩:  缓存穿透是指缓存和数据库中都没有的数据，而用户（黑客）不断发起请求 缓存击穿是指一个Key非常热点，在不停地扛着大量的请求，大并发集中对这一个点进行访问，当这个Key在失效的瞬间，持续的大并发直接落到了数据库上，就在这个Key的点上击穿了缓存。 缓存雪崩是因为大面积的缓存失效，打崩了DBmysql主从复制: https://zhuanlan. zhihu. com/p/342666786  主从复制原理：主从复制中有两个很重要的日志文件，binlog和relay log，分别位于主库与从库中。其中 binlog 是主从复制的基础，通过将操作事件写入 binlog 通过 I/O 线程传送至从库进行同步。 主从延迟原因：     从库中 SQL 线程重放的过程是随机写盘的，并且 SQL 线程是单线程的，因此数据来不及重放的话就会导致主从延迟。   主库并发高会导致写操作不断写入 binlog，对于 SQL 线程说可能会应接不暇，也会产生主从延迟。   重放过程中如果遇到锁等待也是产生延迟的原因之一。    主从延迟处理：MySQL 5. 6版本以后通过并行复制的方式来解决 SQL 单线程产生的主从延迟问题。对于低版本来说，可以通过降低主库的并发来解决。如果对数据实时性要求比较严格的话，可以通过读主库来达到目的。MySQL日记系统redo log、binlog、undo log:  物理日志redo log和逻辑日志binlog redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。 redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2这一行的c字段加1 ”。 redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。数据库高并发解决方法: 1、查询优化  - 尽量减少对数据库的访问次数  - 尽量减少对表的访问行数,最小化结果集  - 能够分开的操作尽量分开处理，提高每次的响应速度  - 在数据窗口使用SQL时，尽量把使用的索引放在选择的首列  - 在查询时，不要过多地使用通配符如SELECT * FROM T1语句，要用到几列就选择几列  - 在可能的情况下尽量限制尽量结果集行数2、部署优化：分库分表 慢查询日志: 慢查询日志是将mysql服务器中影响数据库性能的相关SQL语句记录到日志文件，通过对这些特殊的SQL语句分析，改进以达到提高数据库性能的目的。                通过使用–slow_query_log[={0     1}]选项来启用慢查询日志。所有执行时间超过long_query_time秒的SQL语句都会被记录到慢查询日志。           缺省情况下hostname-slow. log为慢查询日志文件安名，存放到数据目录，同时缺省情况下未开启慢查询日志。 缺省情况下数据库相关管理型SQL(比如OPTIMIZE TABLE、ANALYZE TABLE和ALTER TABLE)不会被记录到日志。 可以使用mysqldumpslow命令获得日志中显示的查询摘要来处理慢查询日志。如何优化SQL:  加索引 避免返回不必要的数据 适当分批量返回 分库分表、读写分离"
    }, {
    "id": 14,
    "url": "/DataStructure/",
    "title": "算法与数据结构",
    "body": "2021/02/05 - 常见算法类型:    排序算法（冒泡、插入、选择、快排、希尔、堆排、归并、桶排、基数、计数）、字符串操作、数组操作、递归、回溯、分治、动态规划等     如何准备算法可见历史文章：进入BAT和字节跳动最难的一关，手撕代码！  排序算法: https://www. cnblogs. com/onepixel/articles/7674659. html  冒泡排序 快速排序  1234567891011121314151617 void QSort(vector&lt;int&gt; &amp;arr, int left, int right) { 	if (left &gt;= right) return; 	int low = left; 	int high = right; 	int key = arr[left]; 	while (left &lt; right) { 		while (left &lt; right &amp;&amp; arr[right] &gt;= key) right--; 		arr[left] = arr[right]; 		while (left &lt; right &amp;&amp; arr[left] &lt;= key) left++; 		arr[right] = arr[left]; 	} 	arr[left] = key; 	QSort(arr, low, left - 1); 	QSort(arr, left + 1, high); }    堆排序 二叉堆本质上是一种完全二叉树，分为最大堆和最小堆。     大顶堆：priority_queue&lt;int&gt;，即 priority_queue&lt;int, vector&lt;int&gt;, less&lt;int&gt;&gt; q;   小顶堆：priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; q;    二叉树前序、中序、后序递归遍历及非递归遍历。     前序遍历：https://leetcode-cn. com/problems/binary-tree-preorder-traversal/   中序遍历：https://leetcode-cn. com/problems/binary-tree-inorder-traversal/   后序遍历：https://leetcode-cn. com/problems/binary-tree-postorder-traversal/   1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class Solution {public:  // 前序，根左右  vector&lt;int&gt; preorderTraversal(TreeNode* root) {    vector&lt;int&gt; ans;    if (root == nullptr) return ans;    stack&lt;TreeNode*&gt; s;    s. push(root);    while (!s. empty()) {      TreeNode* node = s. top();      s. pop();      ans. push_back(node-&gt;val);      if (node-&gt;right) s. push(node-&gt;right);      if (node-&gt;left) s. push(node-&gt;left);    }    return ans;  }  // 中序，左根右  vector&lt;int&gt; inorderTraversal(TreeNode* root) {    vector&lt;int&gt; ans;    if (root == nullptr) return ans;    stack&lt;TreeNode*&gt; s;    TreeNode* node = root;    while (node || !s. empty()) {      while (node) {        s. push(node);        node = node-&gt;left;      }      node = s. top();      s. pop();      ans. push_back(node-&gt;val);      node = node-&gt;right;    }    return ans;  }  // 后续，根右左的逆序  vector&lt;int&gt; postorderTraversal(TreeNode* root) {    vector&lt;int&gt; ans;    if (root == nullptr) return ans;    stack&lt;TreeNode*&gt; s;    s. push(root);    while (!s. empty()) {      TreeNode* node = s. top();      s. pop();      ans. push_back(node-&gt;val);      if (node-&gt;left) s. push(node-&gt;left);      if (node-&gt;right) s. push(node-&gt;right);    }    reverse(ans. begin(), ans. end());    return ans;  }};常用数据结构:  务必熟悉底层原理和实现  链表、栈、队列、树(二叉树、平衡二叉树、红黑树、B树、B+树、哈夫曼树、字典树)、跳表、图AVL树、红黑树: 红黑树：https://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653204996&amp;idx=2&amp;sn=ecf932d2db8cb6e4fcb841a2b6a5bfba&amp;chksm=8c99c0debbee49c86dc8e82a2d195389a93e81d8e5ca8af7d4dd2eec5c7fe209038c91444964&amp;scene=21#wechat_redirectB-树：https://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653190965&amp;idx=1&amp;sn=53f78fa037386f85531832cd5322d2a0&amp;chksm=8c9909efbbee80f90512f0c36356c31cc74c388c46388dc2317d43c8f8597298f233ca9c29e9&amp;scene=21#wechat_redirectB+树：https://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653191027&amp;idx=1&amp;sn=4ba22e3ec8bd149f69fc0aba72e4347e&amp;chksm=8c9909a9bbee80bfa1d8497ff0525df130414c1731b5aa5287bf16ea1cf86c8d8e6f20782184&amp;scene=21#wechat_redirect  AVL树（平衡二叉树）（AVL树得名于它的发明者G. M. Adelson-Velsky和E. M. Landis）本质上还是一棵二叉搜索树，它的特点是：     1. 本身首先是一棵二叉搜索树。   2. 带有平衡条件：每个结点的左右子树的高度之差的绝对值（平衡因子）最多为1。    红黑树是一颗AVL树，同时满足下面的特性：     1. 结点是红色或黑色。   2. 根结点是黑色。   3. 每个叶子结点都是黑色的空结点（NIL结点）。   4 每个红色结点的两个子结点都是黑色。(从每个叶子到根的所有路径上不能有两个连续的红色结点)   5. 从任一结点到其每个叶子的所有路径都包含相同数目的黑色结点。    在需要频繁查找时，选用AVL树更合适，在需要频繁插入删除时，选用红黑树更合适。 一个m阶的B-树具有如下几个特征：     1. 根结点至少有两个子女。   2. 每个中间节点都包含k-1个元素和k个孩子，其中 m/2 &lt;= k &lt;= m   3. 每一个叶子节点都包含k-1个元素，其中 m/2 &lt;= k &lt;= m   4. 所有的叶子结点都位于同一层。   5. 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。    B-树主要用于文件系统以及部分数据库索引，比如著名的非关系型数据库MongoDB。大部分关系型数据库比如MySql则使用B+树作为索引。 一个m阶的B+树具有如下几个特征：     1. 有k个子树的中间节点包含有k个元素（B树中是k-1个元素），每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。   2. 所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。   3. 所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。    B+树的优势：     1. 单一节点存储更多的元素，使得查询的IO次数更少。   2. 所有查询都要查找到叶子节点，查询性能稳定。   3. 所有叶子节点形成有序链表，便于范围查询。   Hash表设计、一致性Hash: 一致性Hash：https://mp. weixin. qq. com/s?__biz=MzIxMjE5MTE1Nw==&amp;mid=2653191083&amp;idx=1&amp;sn=c68c8bb7e18c4d46b85666be10e9ef50&amp;chksm=8c990971bbee80675b6cd0ac3c2c17546cd434c3636616e559ca5cf10d1815c3aed24bfd3c83&amp;scene=21#wechat_redirect Hash表设计： 哈希函数的设计：对于构造哈希来说，主要包括直接地址法、平方取中法、除留余数法等 解决哈希冲突     开放定址法: 开放地址法有个非常关键的特征，就是所有输入的元素全部存放在哈希表里，也就是说，位桶的实现是不需要任何的链表来实现的，换句话说，也就是这个哈希表的装载因子不会超过1。它的实现是在插入一个元素的时候，先通过哈希函数进行判断，若是发生哈希冲突，就以当前地址为基准，根据再寻址的方法（探查序列），去寻找下一个地址，若发生冲突再去寻找，直至找到一个为空的地址为止。所以这种方法又称为再散列法。   再哈希法：当发生哈希冲突时使用另一个哈希函数计算地址值，直到冲突不再发生。这种方法不易产生聚集，但是增加计算时间，同时需要准备许多哈希函数。   链地址法：将所有哈希值相同的Key通过链表存储。key按顺序插入到链表中   建立公共溢出区：建立一个公共溢出区域，把hash冲突的元素都放在该溢出区里。查找时，如果发现hash表中对应桶里存在其他元素，还需要在公共溢出区里再次进行查找。   推荐书籍:    《大话数据结构》适合入门学习     《剑指offer》必刷66题     《算法导论》尽量看，能啃完就是大神  "
    }, {
    "id": 15,
    "url": "/OS/",
    "title": "操作系统",
    "body": "2021/02/04 - 进程、线程、协程:  进程是操作系统资源分配的最小单位，线程是cpu调度的最小单位。 进程有独立的系统资源，而同一进程内的线程共享进程的大部分系统资源,包括堆、代码段、数据段，每个线程只拥有一些在运行中必不可少的私有属性，比如tcb,线程Id,栈、寄存器。 一个进程崩溃，不会对其他进程产生影响；而一个线程崩溃，会让同一进程内的其他线程也死掉。 进程在创建、切换和销毁时开销比较大，而线程比较小。进程创建的时候需要分配系统资源，而销毁的的时候需要释放系统资源。进程切换需要分两步：切换页目录、刷新TLB以使用新的地址空间；切换内核栈和硬件上下文（寄存器）；而同一进程的线程间逻辑地址空间是一样的，不需要切换页目录、刷新TLB。 进程间通信比较复杂，而同一进程的线程由于共享代码段和数据段，所以通信比较容易。 和多线程比，协程最大的优势就是协程极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。 协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。 协程不是被操作系统内核所管理的，而是完全由程序所控制，也就是在用户态执行。这样带来的好处是性能大幅度的提升，因为不会像线程切换那样消耗资源。 协程既不是进程也不是线程，协程仅仅是一个特殊的函数，协程它进程和进程不是一个维度的。 一个进程可以包含多个线程，一个线程可以包含多个协程。 一个线程内的多个协程虽然可以切换，但是多个协程是串行执行的，只能在一个线程内运行，没法利用 CPU 多核能力。进程拥有的资源: 一个进程拥有独立的地址空间（代码段、数据段），打开的文件描述符、自身的信号处理器、所属用户id、进程控制块、进程id、一个或多个线程 进程、线程共享资源:  父子进程共享资源：共享代码段，共享文件（具体而言是共享了文件偏移量）。全局变量、栈区、堆区不共享。     父子进程间的数据共享：读时共享，写时复制。   父子进程之间能够使用全局变量通信？不能，两个进程间内存不能共享。    同一进程间的线程共享的资源有：     堆：由于堆是在进程空间中开辟出来的，所以它是理所当然地被共享的；因此new出来的都是共享的（16位平台上分全局堆和局部堆，局部堆是独享的）   全局变量：它是与具体某一函数无关的，所以也与特定线程无关；因此也是共享的   静态变量：虽然对于局部变量来说，它在代码中是“放”在某一函数中的，但是其存放位置和全局变量一样，存于堆中开辟的. bss和. data段，是共享的   文件等公用资源：这个是共享的，使用这些公共资源的线程必须同步。Win32 提供了几种同步资源的方式，包括信号、临界区、事件和互斥体。    独享的资源有：栈、寄存器。进程的调度算法:  先来先去服务：按照请求的顺序进行调度 短作业优先：按估计运行时间最短的顺序进行调度 最短剩余时间优先：按剩余运行时间的顺序进行调度 时间片轮转法：将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程 优先级调度：为每个进程分配一个优先级，按优先级进行调度。虚拟内存换页的算法有哪些？（页面置换算法）:  https://snailclimb. gitee. io/javaguide/#/docs/operating-system/basis?id=_45-%e9%a1%b5%e9%9d%a2%e7%bd%ae%e6%8d%a2%e7%ae%97%e6%b3%95 缺页中断 就是要访问的页不在主存，需要操作系统将其调入主存后再进行访问。 在这个时候，被内存映射的文件实际上成了一个分页交换文件。 最近最少使用算法（LRU）：指维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾，优先淘汰表尾的页面。 最少频率使用算法（LFU）：它为每个页面设计了一个访问频次计数器，页面每次被访问时，频次加一，优先淘汰频次最小的页面。 先进先出算法（FIFO）：维护一个所有页面的链表，最新进入的页面放在表尾，最早进入的页面放在表头。当发生缺页中断时，淘汰表头的页面，并把新页面加到表尾。缺点是有可能会将经常访问的页面淘汰。 最近未使用算法（NRU）：优先淘汰没有被访问的页面。 第二次机会算法：它对先进先出算法做了改进，当页面被访问时设置该页面的R（Read）位为1。需要替换时，检查最老页面的R位，如果为0，就表示这个页面又老又没有被使用，可以置换掉；如果为1，就将R位清0，并放到链表尾部。 时钟算法：第二次机会算法需要在链表中移动页面，降低了效率，时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。 最优算法：将最长时间内不再被访问的页面置换标记出来，然后把因调用这个页面而发生的缺页中断推迟到将来。是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。进程几种状态，状态转移: IO模型: https://juejin. cn/post/6874898561985839118 阻塞、非阻塞、同步、异步:  阻塞：阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回 非阻塞：非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程 同步：指被调用方得到最终结果之后才返回给调用方 异步：指被调用方先返回应答，然后再计算调用结果，计算完最终结果后再通知并返回给调用方     阻塞、非阻塞的讨论对象是调用者；同步、异步的讨论对象是被调用者。    5种IO模型:  阻塞 IO 模型：应用进程被阻塞，直到数据从内核缓冲区复制到应用进程缓冲区中才返回。  非阻塞IO模型：进程发起 IO 系统调用后，内核返回一个错误码而不会被阻塞；应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成。如果内核缓冲区有数据，内核就会把数据返回进程。  IO 复用模型：使用 select 或者 poll 等待数据，可以等待多个套接字中的任何一个变为可读。这一过程会被阻塞，当某一个套接字可读时返回，之后把数据从内核复制到进程中。（在多路复用 IO 模型中，会有一个线程不断去轮询多个 socket 的状态，只有当 socket 真正有读写事件时，才真正调用实际的 IO 读写操作。因为在多路复用 IO 模型中，只需要使用一个线程就可以管理多个 socket，并且只有在真正有 socket 读写事件进行时，才会使用 IO 资源，所以它大大减少了资源占用。）  信号驱动 IO 模型：当进程发起一个 IO 操作，会向内核注册一个信号处理函数，然后进程返回不阻塞；当内核数据就绪时会发送一个信号给进程，进程便在信号处理函数中调用 IO 读取数据。  异步 IO 模型：当进程发起一个 IO 操作，进程返回不阻塞，但也不能返回结果；内核把整个 IO 处理完后，会通知进程结果。如果IO操作成功则进程直接获取到数据。  select，poll和epoll的区别: https://juejin. cn/post/6844904174862204935 区别:  select()允许程序监视多个文件描述符，直到一个或多个文件描述符准备好进行某些类型的 I/O 操作。如果文件描述符可以不阻塞地执行相应的 I/O 操作(例如，read()或write())，则认为它已经准备好了。 poll 函数和 select 函数的功能类似，它等待一组 fd 中就绪的 I/O。 select，poll 是基于轮询实现的，将 fd_set 从用户空间复制到内核空间，然后让内核空间以 poll 机制来进行轮询，一旦有其中一个fd对应的设备活跃了，那么就把整个fd_set返回给客户端（复制到用户空间），再由客户端来轮询每个fd的，找出发生了IO事件的fd epoll是基于事件驱动实现的，加入一个新的fd，会调用epoll_ctr函数为该fd注册一个回调函数，然后将该fd结点注册到内核中的epoll红黑树中，当IO事件发生时，就会调用回调函数，将该fd结点放到就绪链表中，epoll_wait函数实际上就是从这个就绪链表中获取这些fd。 水平触发、边缘触发     水平触发的意思就是说，只要条件满足，对应的事件就会一直被触发。所以如果条件满足了但未进行处理，那么就会一直被通知   边缘触发的意思就是说，条件满足后，对应的事件只会被触发一次，无论是否被处理，都只会触发一次。   对于select和poll来说，其触发都是水平触发。而epoll则有两种模式：EPOLLLT（水平触发，默认状态）和EPOLLET（边缘触发，效率高）    并不是所有的情况中epoll都是最好的，比如当fd数量比较小的时候，epoll不见得就一定比select和poll好数据结构:  select方法本质其实就是维护了一个文件描述符（fd）数组，以此为基础，实现IO多路复用的功能。这个fd数组有长度限制，在32位系统中，最大值为1024个，而在64位系统中，最大值为2048个。 poll维护了一个链表，所以从理论上，poll方法中，单个进程能监听的fd不再有数量限制 epoll_create会在内核建立一颗专门用来存放fd结点的红黑树进程间通信:  管道 ( pipe )：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。 有名管道 (named pipe) ： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。 信号量 ( semophore ) ： 信号量是一个计数器，可以用来控制多个进程对共享资源的访问。不是用于交换大批数据,而用于多线程之间的同步. 常作为一种锁机制,防止某进程在访问资源时其它进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 消息队列 ( message queue ) ： 消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。 信号 ( signal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。 共享内存 ( shared memory ) ：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号两，配合使用，来实现进程间的同步和通信。 套接字( socket ) ： 套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同机器间的进程通信。线程间通信:  临界区：通过多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问；（每个进程中访问临界资源的那段代码称为临界区（Critical Section）（临界资源是一次仅允许一个进程使用的共享资源）） 互斥量Synchronized/Lock：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问 信号量Semphare：为控制具有有限数量的用户资源而设计的，它允许多个线程在同一时刻去访问同一个资源，但一般需要限制同一时刻访问此资源的最大线程数目。 事件(信号)，Wait/Notify：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作fork 系统调用:  作用：从已经存在的进程中创建一个子进程，原进程称为父进程。 调用 fork()，当控制转移到内核中的 fork 代码后，内核开始做：     分配新的内存块和内核数据结构给子进程。   将父进程部分数据结构内容拷贝至子进程。   将子进程添加到系统进程列表。   fork返回开始调度器，调度。    特点：     调用一次，返回两次并发执行   相同但是独立的地址空间   fork 的返回值：向父进程返回子进程的 pid，向子进程中返回 0，    fork 调用失败的原因     系统中有太多进程。   实际用户的进程数超过限制。   僵尸进程、孤儿进程、守护进程:  孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。孤儿进程并不会有什么危害 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵尸进程。     如果没有调用 wait/waitpid 的话，那么保留的信息就不会释放。比如进程号就会被一直占用了。但系统所能使用的进程号的有限 的，如果产生大量的僵尸进程，将导致系统没有可用的进程号而导致系统不能创建进程。所以我们应该避免僵尸进程   进程一旦调用了wait，就立即阻塞自己，由wait自动分析是否当前进程的某个子进程已经 退出，如果让它找到了这样一个已经变成僵尸的子进程，wait就会收集这个子进程的信息，并把它彻底销毁后返回；如果没有找到这样一个子进程，wait就 会一直阻塞在这里，直到有一个出现为止。    守护进程(daemon)是一类在后台运行的特殊进程，用于执行特定的系统任务。很多守护进程在系统引导的时候启动，并且一直运行直到系统关闭。另一些只在需要的时候才启动，完成任务后就自动结束。物理内存和虚拟内存:  虚拟内存就是说，让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。虚拟内存使用部分加载的技术，让一个进程或者资源的某些页面加载进内存，从而能够加载更多的进程，甚至能加载比内存大的进程，这样看起来好像内存变大了，这部分内存其实包含了磁盘或者硬盘，并且就叫做虚拟内存。虚拟内存:  为了防止不同进程同一时刻在物理内存中运行而对物理内存的争夺和践踏，采用了虚拟内存。 虚拟内存技术使得不同进程在运行过程中，它所看到的是自己独自占有了当前系统的4G内存。所有进程共享同一物理内存，每个进程只把自己目前需要的虚拟内存空间映射并存储到物理内存上。 事实上，在每个进程创建加载时，内核只是为进程“创建”了虚拟内存的布局，具体就是初始化进程控制表中内存相关的链表，实际上并不立即就把虚拟内存对应位置的程序数据和代码（比如. text . data段）拷贝到物理内存中，只是建立好虚拟内存和磁盘文件之间的映射就好（叫做存储器映射），等到运行到对应的程序时，才会通过缺页异常，来拷贝数据。还有进程运行过程中，要动态分配内存，比如malloc时，也只是分配了虚拟内存，即为这块虚拟内存对应的页表项做相应设置，当进程真正访问到此数据时，才引发缺页异常。 请求分页系统、请求分段系统和请求段页式系统都是针对虚拟内存的，通过请求实现内存与外存的信息置换。 虚拟内存的好处：     1. 扩大地址空间；   2. 内存保护：每个进程运行在各自的虚拟内存地址空间，互相不能干扰对方。虚存还对特定的内存地址提供写保护，可以防止代码或数据被恶意篡改。   3. 公平内存分配。采用了虚存之后，每个进程都相当于有同样大小的虚存空间。   4. 当进程通信时，可采用虚存共享的方式实现。   5. 当不同的进程使用同样的代码时，比如库文件中的代码，物理内存中可以只存储一份这样的代码，不同的进程只需要把自己的虚拟内存映射过去就可以了，节省内存   6. 虚拟内存很适合在多道程序设计系统中使用，许多程序的片段同时保存在内存中。当一个程序等待它的一部分读入内存时，可以把CPU交给另一个进程使用。在内存中可以保留多个进程，系统并发度提高   7. 在程序需要分配连续的内存空间的时候，只需要在虚拟内存空间分配连续空间，而不需要实际物理内存的连续空间，可以利用碎片    虚拟内存的代价：     1. 虚存的管理需要建立很多数据结构，这些数据结构要占用额外的内存   2. 虚拟地址到物理地址的转换，增加了指令的执行时间。   3. 页面的换入换出需要磁盘I/O，这是很耗时的   4. 如果一页中只有一部分数据，会浪费内存。   分段和分页、内存管理:  分段和分页共同点：     分页机制和分段机制都是为了提高内存利用率，减少内存碎片。   页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。    分段和分页区别     页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。   分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。    内存管理方式：     块式管理：将内存分为几个固定大小的块，每个块中只包含一个进程。   页式管理：把主存分为大小相等且固定的一页一页的形式，页较小，相对相比于块式管理的划分力度更大，提高了内存利用率，减少了碎片。页式管理通过页表对应逻辑地址和物理地址。   段式管理：页式管理虽然提高了内存利用率，但是页式管理其中的页实际并无任何实际意义。 段式管理把主存分为一段段的，最重要的是段是有实际意义的，每个段定义了一组逻辑信息。 段式管理通过段表对应逻辑地址和物理地址。例如,有主程序段 MAIN、子程序段 X、数据段 D 及栈段 S 等。 段式管理通过段表对应逻辑地址和物理地址。   段页式管理：段页式管理机制结合了段式管理和页式管理的优点。段页式管理机制就是把主存先分成若干段，每个段又分成若干页。   用户态和内核态区别:  根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：     用户态(user mode)：用户态运行的进程或可以直接读取用户程序的数据。   内核态(kernel mode)：可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。    运行的程序基本都是运行在用户态。如果我们调用操作系统提供的内核态级别的子功能那就需要系统调用了。 系统调用：与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。 系统调用是操作系统为应用程序提供能够访问到内核态的资源的接口。 用户态切换到内核态的几种方式     系统调用: 系统调用是用户态主动要求切换到内核态的一种方式， 用户应用程序通过操作系统调用内核为上层应用程序开放的接口来执行程序。   异常：当 cpu 在执行用户态的应用程序时，发生了某些不可知的异常。 于是当前用户态的应用进程切换到处理此异常的内核的程序中去。   硬件设备的中断: 当硬件设备完成用户请求后，会向 cpu 发出相应的中断信号，这时 cpu 会暂停执行下一条即将要执行的指令，转而去执行与中断信号对应的应用程序， 如果先前执行的指令是用户态下程序的指令，那么这个转换过程也是用户态到内核态的转换。    用户态和内核态是操作系统的两种运行级别，两者最大的区别就是特权级不同。用户态拥有最低的特权级，内核态拥有较高的特权级。运行在用户态的程序不能直接访问操作系统内核数据结构和程序。内核态和用户态之间的转换方式主要包括：系统调用，异常和中断。Linux系统操作和命令:  top命令 ps命令 netstat命令 awk命令 find命令 grep命令 wc命令 sed命令 head和tail命令 正则表达式 如何查找出现频率最高的100个IP地址 linux如何统计文件中某个字符串出现的频率 linux启动的第一个进程 linux查看端口占用 linux查看CPU和内存使用 Linux查看系统负载命令 Linux调试程序 Linux硬链接和软连接 core dump cmake和makefile Shell脚本基本语法和使用硬链接和软链接:  硬链接： 硬连接指通过索引节点 inode 来进行的连接，即每一个硬链接都是一个指向对应区域的文件。硬链接等于cp -p 加 同步更新。 软链接： 保存了其代表的文件的绝对路径，是另外一种文件，在硬盘上有独立的区块， 访问时替换自身路径。软链接可以理解成快捷方式。它和windows下的快捷方式的作用是一样的。 新建硬链接：ln 源文件 目标文件 新建软链接：ln -s 【目标目录】 【软链接地址】 修改软链接：ln -snf 【新目标目录】 【软链接地址】死锁:  线程死锁描述的是这样一种情况：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。 死锁条件：1）互斥条件、2）请求和保持条件、3）不剥夺条件、4）环路等待条件 解决死锁的策略：     死锁预防：破坏导致死锁必要条件中的任意一个就可以预防死锁。例如：         破坏保持和等待条件：一次性申请所有资源，之后不再申请资源，如果不满足资源条件则得不到资源分配。     破坏不可剥夺条件：当一个进程获得某个不可剥夺的资源时，提出新的资源申请，若不满足，则释放所有资源。     破坏循环等待条件：按某一顺序申请资源，释放资源则反序释放。          死锁避免：进程在每次申请资源时判断这些操作是否安全。   死锁检测：判断系统是否属于死锁的状态，如果是，则执行死锁解除策略。   死锁解除：将某进程所占资源进行强制回收，然后分配给其他进程。（与死锁检测结合使用的）    独享锁/共享锁(互斥锁/读写锁)：独享锁是指该锁一次只能被一个线程所持有。共享锁是指该锁可被多个线程所持有。共享锁：std::shared_lock&lt;std::shared_mutex&gt;，独享所：std::unique_lock&lt;std::shared_mutex&gt;。 乐观锁/悲观锁：     悲观锁：之所以叫做悲观锁，是因为这是一种对数据的修改持有悲观态度的并发控制方式。总是假设最坏的情况，每次读取数据的时候都默认其他线程会更改数据，因此需要进行加锁操作，当其他线程想要访问数据时，都需要阻塞挂起。悲观锁的实现：传统的关系型数据库使用这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。   乐观锁：乐观锁假设数据一般情况下不会造成冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回给用户错误的信息，让用户决定如何去做。乐观锁适用于读操作多的场景，这样可以提高程序的吞吐量。   悲观锁适合写操作非常多的场景，乐观锁适合读操作非常多的场景，不加锁会带来大量的性能提升。    自旋锁：自旋锁是指尝试获取锁的线程不会立即阻塞，而是采用循环的方式去尝试获取锁，这样 的好处是减少线程上下文切换的消耗，缺点是循环会消耗CPU。```#include #include #include struct spinlock{  volatile std::atomic_flag lck; 123456789101112131415161718spinlock(){  lck. clear();}void lock(){  while (std::atomic_flag_test_and_set_explicit(&amp;lck, std::memory_order_acquire)){    std::this_thread::yield();  }}bool try_lock(){  bool ret = !std::atomic_flag_test_and_set_explicit(&amp;lck, std::memory_order_acquire);  return ret;}void unlock(){  std::atomic_flag_clear_explicit(&amp;lck, std::memory_order_release);} }; ```正向代理、反向代理:  正向代理类似一个跳板机，代理访问外部资源。比如我们国内访问谷歌，直接访问访问不到，我们可以通过一个正向代理服务器，请求发到代理服，代理服务器能够访问谷歌，这样由代理去谷歌取到返回数据，再返回给我们，这样我们就能访问谷歌了 反向代理（Reverse Proxy）实际运行方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器 反向代理的作用：     保证内网的安全，阻止web攻击，大型网站，通常将反向代理作为公网访问地址，Web服务器是内网   负载均衡，通过反向代理服务器来优化网站的负载    正向代理即是客户端代理, 代理客户端, 服务端不知道实际发起请求的客户端反向代理即是服务端代理, 代理服务端, 客户端不知道实际提供服务的服务端 并发和并行:  并发（Concurrent），在操作系统中，是指一个时间段中有几个程序都处于已启动运行到运行完毕之间，且这几个程序都是在同一个处理机上运行。 并行（Parallel），当系统有一个以上CPU时，当一个CPU执行一个进程时，另一个CPU可以执行另一个进程，两个进程互不抢占CPU资源，可以同时进行，这种方式我们称之为并行(Parallel)。重点掌握: 11:    缓存IO和直接IO     进程和线程的调度     线程状态     消费者和生产者  推荐书籍:  《深入理解计算机系统》很全面的书，这一本就够用了"
    }, {
    "id": 16,
    "url": "/Redis/",
    "title": "Redis",
    "body": "2021/02/02 - 1、数据结构: 1. 1 SDS：Simple Dynamic Strings: 1234567891011121314151617181920212223242526272829303132333435363738typedef char *sds;/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */struct __attribute__ ((__packed__)) sdshdr5 {  unsigned char flags; /* 3 lsb of type, and 5 msb of string length */  char buf[];};struct __attribute__ ((__packed__)) sdshdr8 {  uint8_t len; /* used */  uint8_t alloc; /* excluding the header and null terminator */  unsigned char flags; /* 3 lsb of type, 5 unused bits */  char buf[];};struct __attribute__ ((__packed__)) sdshdr16 {  uint16_t len; /* used */  uint16_t alloc; /* excluding the header and null terminator */  unsigned char flags; /* 3 lsb of type, 5 unused bits */  char buf[];};struct __attribute__ ((__packed__)) sdshdr32 {  uint32_t len; /* used */  uint32_t alloc; /* excluding the header and null terminator */  unsigned char flags; /* 3 lsb of type, 5 unused bits */  char buf[];};struct __attribute__ ((__packed__)) sdshdr64 {  uint64_t len; /* used */  uint64_t alloc; /* excluding the header and null terminator */  unsigned char flags; /* 3 lsb of type, 5 unused bits */  char buf[];};#define SDS_TYPE_5 0#define SDS_TYPE_8 1#define SDS_TYPE_16 2#define SDS_TYPE_32 3#define SDS_TYPE_64 4 len：表示buf中已占用字节数。 alloc：表示buf中已分配字节数，不同于free，记录的是位buf分配的总长度。 flags：表示当前结构体的类型，低3位用作标识位，高5位保留。 buf：柔性数组，真正存储字符串的数据空间。 sdshdr5 只负责存储小于32字节的字符串。sdshdr5 的类型和长度存储于 flags 中，低3位存储类型，高5位存储长度。sdshdr16结构 1. 2 跳跃表 skiplist:  跳跃表是Redis有序集合的底层实现方式之一。123456789101112131415typedef struct zskiplistNode {  sds ele;    // 存储字符串类型的数据  double score;  // 存储排序的分值  struct zskiplistNode *backward;   // 后退指针，指向当前节点最底层的前一个节点，头节点和第一个节点的backward指向NULL，从后向前遍历跳跃表时使用。  struct zskiplistLevel {    struct zskiplistNode *forward; // 指向本层的下一个节点，尾节点的forward指向NULL    unsigned long span;       // forward节点指向的节点和本节点之间的元素个数。span越大，跳过的节点个数越多。  } level[];   // 每个节点的数组长度不一样，在生成跳跃表时，随机生成一个1-64的值，值越大出现的概率越低。} zskiplistNode;typedef struct zskiplist {  struct zskiplistNode *header, *tail;// 表头、表尾节点。头结点是一个特殊的节点，它的level数组元素个数是64。头结点不存储数据，不计入跳跃表长度  unsigned long length;        // 跳跃表长度，表示出头节点之外的节点总数  int level;             // 跳跃表的高度} zskiplist; 新增节点通过 zslRandomLevel 函数随机生成一个1-64的值，作为新建节点的高度，值越大出现的概率越低。节点层高确定之后不会再修改。跳跃表示例 1. 3 压缩列表 ziplist:  ziplist本质上是一个字节数组，是redis为节约内存设计的一种线性数据结构，可以包含多个元素，每个元素可以是一个字节数组或一个整数。压缩列表结构示意图 1234567891011121314151617181920212223242526272829303132333435363738/* * The following is a ziplist containing the two elements representing * the strings  2  and  5 . It is composed of 15 bytes, that we visually * split into sections: * * [0f 00 00 00] [0c 00 00 00] [02 00] [00 f3] [02 f6] [ff] *    |       |     |    |    |   | *   zlbytes    zltail  entries   2     5   end * * The first 4 bytes represent the number 15, that is the number of bytes * the whole ziplist is composed of. The second 4 bytes are the offset * at which the last ziplist entry is found, that is 12, in fact the * last entry, that is  5 , is at offset 12 inside the ziplist. * The next 16 bit integer represents the number of elements inside the * ziplist, its value is 2 since there are just two elements inside. * Finally  00 f3  is the first entry representing the number 2. It is * composed of the previous entry length, which is zero because this is * our first entry, and the byte F3 which corresponds to the encoding * |1111xxxx| with xxxx between 0001 and 1101. We need to remove the  F  * higher order bits 1111, and subtract 1 from the  3 , so the entry value * is  2 . The next entry has a prevlen of 02, since the first entry is * composed of exactly two bytes. The entry itself, F6, is encoded exactly * like the first entry, and 6-1 = 5, so the value of the entry is 5. * Finally the special entry FF signals the end of the ziplist. * * Adding another element to the above string with the value  Hello World  * allows us to show how the ziplist encodes small strings. We'll just show * the hex dump of the entry itself. Imagine the bytes as following the * entry that stores  5  in the ziplist above: * * [02] [0b] [48 65 6c 6c 6f 20 57 6f 72 6c 64] * * The first byte, 02, is the length of the previous entry. The next * byte represents the encoding in the pattern |00pppppp| that means * that the entry is a string of length &lt;pppppp&gt;, so 0B means that * an 11 bytes string follows. From the third byte (48) to the last (64) * there are just the ASCII characters for  Hello World . */ zlbytes：压缩列表的字节长度，占4个字节，因此压缩列表最多有2^32-1个字节。 zltail：压缩列表尾元素相对于压缩列表起始地址的偏移量，占4个字节。 zllen：压缩列表的元素个数，占2个字节。zllen无法存储超过2^16-1个元素，当值为UINT16_MAX时，必须遍历整个压缩列表才能获取到元素个数。 entryX：压缩列表存储的元素，可以是字节数组或整数，长度不限。 zlend：压缩列表的结尾，占一个字节，恒为0xFF压缩列表元素结构示意图  previous_entry_length：表示前一个元素的字节长度，占1个或5个字节。当前一个元素长度&lt;254字节时，用1个字节表示；当前一个元素长度&gt;=254字节时，用5个字节表示，此时第一个字节固定是0xFE，后4个字节才是真正的前一个元素长度值。 encoding：表示当前元素的编码，即content存储的数据类型（整数或字节数组）压缩列表元素编码  在下图的压缩列表zl1中，删除P1位置的节点entryX，在压缩列表zl2中，P2位置插入节点entryY，会导致连锁更新。压缩列表连锁更新示意图 1. 4 字典: 字典结构示意图 123456789101112131415161718192021222324252627typedef struct dictEntry {  void *key;       // 存储键  union {    void *val;     // db. dict中的val    uint64_t u64;    int64_t s64;    // db. expires中存储过期时间    double d;  } v;  struct dictEntry *next; // 当hash冲突时，指向冲突的元素，形成单链表} dictEntry;/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht {  dictEntry **table;  unsigned long size;  unsigned long sizemask;  unsigned long used;} dictht;typedef struct dict {  dictType *type; // 该字典对应的特定操作函数  void *privdata; // 该字典依赖的数据  dictht ht[2];  // hash表，键值对存储于此  long rehashidx; // rehash标识。默认值为-1，表示没有进行rehash操作。不为-1时，标识正在进行rehash操作，存储的值表示hash表ht[0]的rehash操作进行到了哪个索引值  unsigned long iterators;  // 记录当前运行的安全迭代器数。当有安全迭代器绑定到该字典时，会暂定rehash操作。} dict;1. 4. 1 渐进式rehash: rehash除了扩容时会触发，缩容时也会触发。Redis整个rehash的实现，主要分为如下几步完成。  1）给Hash表 ht[1] 申请足够的空间；扩容时空间大小为当前容量*2，即 d-&gt;ht[0]. used * 2；当使用量不到总空间10%时，则进行缩容。缩容时空间大小则为能恰好包含 d-&gt;ht[0]. used 个节点的2^N次方幂整数，并把字典中字段 rehashidx 标识为0。 2）进行rehash操作调用的是 dictRehash 函数，重新计算 ht[0] 中每个键的Hash值与索引值（重新计算就叫rehash），依次添加到新的Hash表 ht[1] ，并把老Hash表中该键值对删除。把字典中字段 rehashidx 字段修改为Hash表 ht[0] 中正在进行rehash操作节点的索引值。 3）rehash操作后，清空 ht[0]，然后对调一下 ht[1] 与 ht[0] 的值，并把字典中 rehashidx 字段标识为-1。1. 5 intset:  当集合中元素都是整型，并且元素个数小于512个（默认配置值 set-max-intset-entries）时，用intset保存。并且元素从小到大保存。123456789  typedef struct intset {    uint32_t encoding; // 编码类型    uint32_t length;  // 元素个数    int8_t contents[];  } intset;  #define INTSET_ENC_INT16 (sizeof(int16_t))  #define INTSET_ENC_INT32 (sizeof(int32_t))  #define INTSET_ENC_INT64 (sizeof(int64_t))1. 6 quicklist:  quicklist 由 List 和 ziplist 结合而成。quicklist结构示意图 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* quicklistNode is a 32 byte struct describing a ziplist for a quicklist. * We use bit fields keep the quicklistNode at 32 bytes. * count: 16 bits, max 65536 (max zl bytes is 65k, so max count actually &lt; 32k). * encoding: 2 bits, RAW=1, LZF=2. * container: 2 bits, NONE=1, ZIPLIST=2. * recompress: 1 bit, bool, true if node is temporarry decompressed for usage. * attempted_compress: 1 bit, boolean, used for verifying during testing. * extra: 10 bits, free for future use; pads out the remainder of 32 bits */typedef struct quicklistNode {  struct quicklistNode *prev;  struct quicklistNode *next;  unsigned char *zl;  unsigned int sz;       /* ziplist size in bytes */  unsigned int count : 16;   /* count of items in ziplist */  unsigned int encoding : 2;  /* RAW==1 or LZF==2 */                 /* 2表示使用LZF进行压缩，此时zl指向的结构为quicklistLZF */  unsigned int container : 2; /* NONE==1 or ZIPLIST==2 */  unsigned int recompress : 1; /* was this node previous compressed? */                 /* 1表示该节点之前被压缩过，使用时需要解压使用，用完再压缩 */  unsigned int attempted_compress : 1; /* node can't compress; too small */  unsigned int extra : 10; /* more bits to steal for future usage */} quicklistNode;/* quicklistLZF is a 4+N byte struct holding 'sz' followed by 'compressed'. * 'sz' is byte length of 'compressed' field. * 'compressed' is LZF data with total (compressed) length 'sz' * NOTE: uncompressed length is stored in quicklistNode-&gt;sz. * When quicklistNode-&gt;zl is compressed, node-&gt;zl points to a quicklistLZF */typedef struct quicklistLZF {  unsigned int sz; /* LZF size in bytes*/  char compressed[];} quicklistLZF;/* quicklist is a 40 byte struct (on 64-bit systems) describing a quicklist. * 'count' is the number of total entries. * 'len' is the number of quicklist nodes. * 'compress' is: -1 if compression disabled, otherwise it's the number *        of quicklistNodes to leave uncompressed at ends of quicklist. * 'fill' is the user-requested (or default) fill factor. */typedef struct quicklist {  quicklistNode *head;  quicklistNode *tail;  unsigned long count;    /* total count of all entries in all ziplists */                /* 所有 ziplist 中 entry 的总数 */  unsigned long len;     /* number of quicklistNodes */  int fill : 16;       /* fill factor for individual nodes */                /* 指明每个 quicklistNode 中 ziplist 长度。*/                /* 正数时表示每个 ziplist 最多包含的 entry 个数。 */                /* 负数时表示 ziplist 节点占用内存大小，-1~-5分别表示4/8/16/32/64KB */  unsigned int compress : 16; /* depth of end nodes not to compress;0=off */} quicklist;1. 7 Redis数据结构: 1. 7. 1 String:  int、raw、embstr. 1. 7. 2 List:  quicklist1. 7. 3 Hash:  ziplist、hashtable 当同时满足下面两个条件时，采用ziplist作为底层存储，否则需要转换为散列表存储。值得注意的是，ziplist的存储顺序与插入顺序一致，而散列表的存储则不一致。     key-value结构的所有键值对的字符串长度都小于 hash-max-ziplist-value （默认值64），该值可以通过配置文件配置。   散列对象保存的键值对的个数（一个键值对记为1个）小于 hash-max-ziplist-entries （默认值512），该值也可以通过配置文件配置。   1. 7. 4 Set:  集合元素为字符串和数字，分别用 dict 和 intset 存储1. 7. 5 SortedSet:  用到的数据结构是ziplit、dict、skiplist。 zset-max-ziplist-entries 128：zset采用压缩列表时，元素个数的最大值。默认128。 zset-max-ziplist-value 64：zset采用压缩列表时，每个元素的字符串长度的最大值。默认64。 创建zset时，默认使用ziplist底层实现，新插入元素时，满足以下条件任意一个，则将zset底层实现由ziplist转为skiplist，且不再转回ziplist：     zset中元素个数大于 zset-max-ziplist-entries   插入元素的字符串长度大于 zset-max-ziplist-value   1. 7. 5 HyperLogLog:  pfadd、pfcount、pfmerge 用来做基数统计，每个key用12KB内存，计算接近2^64个不同的元素。 可用于统计网站UV（去重统计访问页面人数）1. 7. 6 Bitmap:  setbit、getbit、bitcount 可用于统计用户每日签到等。2、Redis高可用:  在Redis(Remote Dictionary Server)中，实现高可用的技术主要包括持久化、复制、哨兵和集群，下面分别说明它们的作用，以及解决了什么样的问题：     持久化：持久化是最简单的高可用方法，有时甚至不被归为高可用的手段，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。   复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制。   哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷是写操作无法负载均衡、存储能力受到单机的限制。   集群：通过集群，Redis解决了写操作无法负载均衡以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。   2. 1、持久化:  AOF开启时，Redis启动时会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会载入RDB文件恢复数据。  2. 1. 1 RDB:   RDB持久化是将当前进程中的数据生成快照保存到硬盘（因此也称作快照持久化），保存的文件后缀是rdb；当Redis重新启动时，可以读取快照文件恢复数据。 RDB持久化的触发分为手动触发和自动触发两种。     手动触发：save命令和bgsave命令都可以生成RDB文件。save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程(即Redis主进程)则继续处理请求。bgsave命令执行过程中，只有fork子进程时会阻塞服务器，而对于save命令，整个过程都会阻塞服务器，因此save已基本被废弃，线上环境要杜绝save的使用。   自动触发：自动触发最常见的情况是在配置文件中通过 save m n，指定当m秒内发生n次变化时，会触发bgsave。   save m n 的原理如下：每隔100ms，执行serverCron函数；在serverCron函数中，遍历save m n配置的保存条件，只要有一个条件满足，就进行bgsave。对于每一个save m n条件，只有下面两条同时满足时才算满足：         当前时间-lastsave &gt; m（lastsave时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。）     dirty &gt;= n（dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。）           除了 save m n 以外，还有一些其他情况会触发bgsave：     在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点；   执行shutdown命令时，自动执行rdb持久化    小结       RDB文件用于保存和还原Redis服务器所有数据库中的所有键值对数据。 SAVE命令由服务器进程直接执行保存操作，所以该命令会阻塞服务器。 BGSAVE令由子进程执行保存操作，所以该命令不会阻塞服务器。 服务器状态中会保存所有用save选项设置的保存条件，当任意一个保存条件被满足时，服务器会自动执行BGSAVE命令。 RDB文件是一个经过压缩的二进制文件，由多个部分组成。 对于不同类型的键值对，RDB文件会使用不同的方式来保存它们。2. 1. 2 AOF:  RDB持久化是将进程数据写入文件，而AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中（有点像MySQL的binlog）；当Redis重启时再次执行AOF文件中的命令来恢复数据。 Redis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：appendonly yes AOF的执行流程包括：  2. 1. 2. 1 命令追加(append)  将Redis的写命令追加到缓冲区aof_buf；  2. 1. 2. 2 文件写入(write)和文件同步(sync)  根据不同的同步策略将aof_buf中的内容同步到硬盘；AOF缓存区的同步文件策略由参数 appendfsync 控制，各个值的含义如下：     no：不执行fsync，由操作系统负责数据的刷盘。数据安全性最低但Redis性能最高。   always：每执行一次写入就会执行一次fsync。数据安全性最高但会导致Redis性能降低。   everysec：每1秒执行一次fsync操作。属于折中方案，在数据安全性和性能之间达到一个平衡。    生产环境一般配置为 appendfsync everysec，即每秒执行一次fsync操作。  2. 1. 2. 3 文件重写(rewrite)：定期重写AOF文件，达到压缩的目的。  有2种触发方式：     自动触发：auto-aof-rewrite-percentage 100，auto-aof-rewrite-min-size 64mb，当AOF文件大于64MB时，并且AOF文件当前大小比基准大小增长了100%时会触发一次AOF重写。起始的基准大小为Redis重启并加载完AOF文件之后，aof_buf的大小。当执行完一次AOF重写之后，基准大小相应更新为重写之后AOF文件的大小。   手动触发：执行 bgrewriteaof 命令。    虽然Redis将生成新AOF文件替换旧AOF文件的功能命名为“AOF文件重写”，但实际上，AOF文件重写并不需要对现有的AOF文件进行任何读取、分析或者写入操作，这个功能是通过读取服务器当前的数据库状态来实现的。首先从数据库中读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令，这就是AOF重写功能的实现原理。 如果服务端执行一条命令时正在执行AOF重写，命令还会同步到AOF重写缓冲区 aof_rewrite_buf_blocks 中，这个缓冲区在服务器创建子进程之后开始使用，当Redis服务器执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。 当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接到该信号之后，会调用一个信号处理函数，并执行以下工作：     1）将AOF重写缓冲区中的所有内容写入到新AOF文件中，这时新AOF文件所保存的数据库状态将和服务器当前的数据库状态一致。   2）对新的AOF文件进行改名，原子地（atomic）覆盖现有的AOF文件，完成新旧两个AOF文件的替换。 这个信号处理函数执行完毕之后，父进程就可以继续像往常一样接受命令请求了。    2. 1. 2. 4 小结       AOF文件通过保存所有修改数据库的写命令请求来记录服务器的数据库状态。 AOF文件中的所有命令都以Redis命令请求协议的格式保存。 命令请求会先保存到AOF缓冲区里面，之后再定期写入并同步到AOF文件。 appendfsync选项的不同值对AOF持久化功能的安全性以及Redis服务器的性能有很大的影响。 服务器只要载入并重新执行保存在AOF文件中的命令，就可以还原数据库本来的状态。 AOF重写可以产生一个新的AOF文件，这个新的AOF文件和原有的AOF文件所保存的数据库状态一样，但体积更小。 AOF重写是一个有歧义的名字，该功能是通过读取数据库中的键值对来实现的，程序无须对现有AOF文件进行任何读入、分析或者写入操作。 在执行BGREWRITEAOF命令时，Redis服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建新AOF文件期间，记录服务器执行的所有写命令。当子进程完成创建新AOF文件的工作之后，服务器会将重写缓冲区中的所有内容追加到新AOF文件的末尾，使得新旧两个AOF文件所保存的数据库状态一致。最后，服务器用新的AOF文件替换旧的AOF文件，以此来完成AOF文件重写操作。2. 1. 3 混合持久化:  重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。 Redis 4. 0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是 自持久化开始到持久化结束 的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小： 于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。2. 2 主从复制:  主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器 Redis 主从复制支持 主从同步 和 从从同步 两种，后者是 Redis 后续版本新增的功能，以减轻主节点的同步负担。 2. 8版本之前的主从同步流程图sequenceDiagram  participant c as 客户端  participant s as 从服务器  participant m as 主服务器  c-&gt;&gt;s: slaveof master_ip master_port  note left of s: 让master成为slave的主服务器  s-&gt;&gt;m: ping  m--&gt;&gt;s: pong  s-&gt;&gt;m: SYNC  note left of s: 开始请求同步数据  m-&gt;&gt;m: bgsave生成rdb文件  note left of m: 同时用一个缓冲区记录从现在开始执行的所有命令  m-&gt;&gt;s: 将rdb文件发给从服务器  s-&gt;&gt;s: 载入rdb文件  m-&gt;&gt;s: 发送缓冲区中的命令  s-&gt;&gt;s: 执行收到的命令 2. 8版本及以上版本PSYNC主从复制主从复制初始化流程图  其中RUN_ID是主服务器id，由40个随机的16进制字符组成，OFFSET是复制偏移量 slaveof no one 断开复制，不会删除已有的数据。 主节点配置 requirepass 来设置密码，从节点配置 masterauth 参数 (与主节点 requirepass 保持一致)，保证安全。 Redis 2. 8以前的复制功能不能高效地处理断线后重复制情况，但Redis 2. 8新添加的部分重同步功能可以解决这个问题。使用PSYNC命令代替SYNC命令。 部分重同步通过复制偏移量、复制积压缓冲区、服务器运行ID三个部分来实现。 在复制操作刚开始的时候，从服务器会成为主服务器的客户端，并通过向主服务器发送命令请求来执行复制步骤，而在复制操作的后期，主从服务器会互相成为对方的客户端。 主服务器通过向从服务器传播命令来更新从服务器的状态，保持主从服务器一致，而从服务器则通过向主服务器发送命令来进行心跳检测，以及命令丢失检测。2. 3 哨兵: 哨兵部署方案2. 3. 1 哨兵功能：:  监控（Monitoring）： 哨兵会不断地检查主节点和从节点是否运作正常。 自动故障转移（Automatic failover）： 当 主节点 不能正常工作时，哨兵会开始 自动故障转移操作，它会将失效主节点的其中一个 从节点升级为新的主节点，并让其他从节点改为复制新的主节点。 配置提供者（Configuration provider）： 客户端在初始化时，通过连接哨兵来获得当前 Redis 服务的主节点地址。 通知（Notification）： 哨兵可以将故障转移的结果发送给客户端。2. 3. 2 主从切换: 检测主观下线：在默认情况下，Sentinel会以每秒一次的频率向所有与它创建了命令连接的实例（包括主服务器、从服务器、其他Sentinel在内）发送PING命令，并通过实例返回的PING命令回复来判断实例是否在线。Sentinel配置文件中的 down-after-milliseconds 选项指定了Sentinel判断实例进入主观下线所需的时间长度：如果一个实例在down-after-milliseconds毫秒内，连续向Sentinel返回无效回复，那么Sentinel会修改这个实例所对应的实例结构，在结构的flags属性中打开SRI_S_DOWN标识，以此来表示这个实例已经进入主观下线状态。 检查客观下线：当Sentinel将一个主服务器判断为主观下线之后，为了确认这个主服务器是否真的下线了，它会向同样监视这一主服务器的其他Sentinel进行询问，看它们是否也认为主服务器已经进入了下线状态（可以是主观下线或者客观下线）。当Sentinel从其他Sentinel那里接收到足够数量的已下线判断之后，Sentinel就会将从服务器判定为客观下线，并对主服务器执行故障转移操作。当认为主服务器已经进入下线状态的Sentinel的数量，超过Sentinel配置中设置的quorum参数的值，那么该Sentinel就会认为主服务器已经进入客观下线状态。 选举领头Sentinel：当一个主服务器被判断为客观下线时，监视这个下线主服务器的各个Sentinel会进行协商，选举出一个领头Sentinel，并由领头Sentinel对下线主服务器执行故障转移操作。 哨兵使用以下规则来选择新的主服务器：  淘汰那些被标记为主观下线、已断线、或者最后一次回复 PING 命令的时间大于五秒钟的从服务器。 如果 slave-priority 为0，则不能被选中（slave-priority 可以在配置文件中指定。正整数，值越小优先级越高，当指定为0时，不能被选为主服务器） 淘汰与失效主服务器连接断开的时长超过 down-after-milliseconds*10 ms 的从服务器。 优先 slave-priority 高的，其次复制偏移量（replication offset）最大，再次带有最小运行 ID 的从服务器2. 4 集群: 集群部署方式 在客户端执行 cluster meet &lt;ip&gt; &lt;port&gt; 构建集群。 通过 cluster-enable 配置决定是否开启集群模式。 整个数据库被分成16384个槽。cluster addslots 将一个或多个槽指派给当前节点负责。节点会将自己负责的槽告知给集群中其它节点。16384个槽都进行了指派，集群才会进入上线状态。 客户端查询key时，接收命令的节点先计算槽，是自己的则处理，不是则返回MOVED错误，格式为：MOVED &lt;slot&gt; &lt;ip&gt;:&lt;port&gt;，客户端收到后会向返回的ip和port请求。计算槽的公式为：CRC16(key) &amp; 16383。通过 cluster keyslot &lt;key&gt; 可以查看key属于哪个slot。主从切换:  集群之间会互相发送心跳包，心跳包中会包括从发送方视角所记录的关于其他节点的状态信息。当一个节点收到心跳包之后，如果检测到发送方（假设为A）标记某个节点（假设为B）处于pfail状态，则接收节点（假设为C）会检测B是否已经被大多数主节点标记为pfail状态。如果是，则C节点会向集群中所有节点发送一个fail包，通知其他节点B已经处于fail状态。 当一个主节点（假设为B）被标记为fail状态后，该主节点的所有Slave执行周期性函数clusterCron时，会从所有的Slave中选择一个复制偏移量最大的Slave节点（即数据最新的从节点，假设为D），然后D节点首先将其当前纪元（currentEpoch）加1，然后向所有的主节点发送failover授权请求包，当获得大多数主节点的授权后，开始执行主从切换。 手动切换：当一个从节点接收到 cluster failover 命令之后，执行手动切换。副本漂移: 集群副本漂移我们只给其中一个主C增加两个从服务。假设主A发生故障，主A的从A1会执行切换，切换完成之后从A1变为主A1，此时主A1会出现单点问题。当检测到该单点问题后，集群会主动从主C的从服务中漂移一个给有单点问题的主A1做从服务。 分片迁移:  增加或删除节点都会进行分片迁移（slot迁移），即将该节点提供服务的分片迁移到其它节点。     在节点A执行 CLUSTER SETSLOT slot MIGRATING node，将slot从A节点迁移到指定的node节点。注意，slot必须属于A节点，否则会报错。   CLUSTER SETSLOT slot IMPORTING node：将slot从指定节点迁移到A节点。   3、过期键删除策略:  如果一个键过期了，那么它什么时候会被删除呢？     定时删除：在设置键的过期时间的同时，创建一个定时器（timer），让定时器在键的过期时间来临时，立即执行对键的删除操作。   惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。   定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。至于要删除多少过期键，以及要检查多少个数据库，则由算法决定。    Redis服务器实际使用的是惰性删除和定期删除两种策略：通过配合使用这两种删除策略，服务器可以很好地在合理使用CPU时间和避免浪费内存空间之间取得平衡。4、淘汰策略: Redis的内存淘汰策略是指在Redis的用于缓存的内存不足时，怎么处理需要新写入且需要申请额外空间的数据。  volatile-lru：从已设置过期时间的数据集（server. db[i]. expires）中挑选最近最少使用的数据淘汰 volatile-lfu：挑选使用频率最低的数据淘汰 volatile-random：随机淘汰 volatile-ttl：挑选将要过期的数据淘汰 allkeys-lru：从数据集（server. db[i]. dict）中挑选最近最少使用的数据淘汰 allkeys-lfu：挑选使用频率最低的数据淘汰 allkeys-random：随机淘汰5、发布订阅: 12订阅：subscribe channel_name发布：publish channel_name message6、分布式锁:  setnx (set if not exists)，setnx加expire可能会死锁 2. 8版本及之后：set keyname val ex 5 nx，当keyname不存在时，设置key，过期时间为5秒"
    }, {
    "id": 17,
    "url": "/Algorithm/",
    "title": "算法框架模版",
    "body": "2020/11/11 - BFS算法框架: 12345678910111213141516171819202122232425262728// 计算从起点 start 到终点 target 的最近距离int BFS(Node start, Node target) {  Queue&lt;Node&gt; q; // 核心数据结构  Set&lt;Node&gt; visited; // 避免走回头路  q. offer(start); // 将起点加入队列  visited. add(start);  int step = 0; // 记录扩散的步数  while (q not empty) {    int sz = q. size();    /* 将当前队列中的所有节点向四周扩散 */    for (int i = 0; i &lt; sz; i++) {      Node cur = q. poll();      /* 划重点：这里判断是否到达终点 */      if (cur is target)        return step;      /* 将 cur 的相邻节点加入队列 */      for (Node x : cur. adj())        if (x not in visited) {          q. offer(x);          visited. add(x);        }    }    /* 划重点：更新步数在这里 */    step++;  }}动态规划算法框架: 1234567## 初始化 base casedp[0][0][. . . ] = base## 进行状态转移for 状态1 in 状态1的所有取值：  for 状态2 in 状态2的所有取值：    for . . .       dp[状态1][状态2][. . . ] = 求最值(选择1，选择2. . . )二分查找模版: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354int binary_search(int[] nums, int target) {  int left = 0, right = nums. length - 1;  while(left &lt;= right) {    int mid = left + (right - left) / 2;    if (nums[mid] &lt; target) {      left = mid + 1;    } else if (nums[mid] &gt; target) {      right = mid - 1;    } else if(nums[mid] == target) {      // 直接返回      return mid;    }  }  // 直接返回  return -1;}int left_bound(int[] nums, int target) {  int left = 0, right = nums. length - 1;  while (left &lt;= right) {    int mid = left + (right - left) / 2;    if (nums[mid] &lt; target) {      left = mid + 1;    } else if (nums[mid] &gt; target) {      right = mid - 1;    } else if (nums[mid] == target) {      // 别返回，锁定左侧边界      right = mid - 1;    }  }  // 最后要检查 left 越界的情况  if (left &gt;= nums. length || nums[left] != target)    return -1;  return left;}int right_bound(int[] nums, int target) {  int left = 0, right = nums. length - 1;  while (left &lt;= right) {    int mid = left + (right - left) / 2;    if (nums[mid] &lt; target) {      left = mid + 1;    } else if (nums[mid] &gt; target) {      right = mid - 1;    } else if (nums[mid] == target) {      // 别返回，锁定右侧边界      left = mid + 1;    }  }  // 最后要检查 right 越界的情况  if (right &lt; 0 || nums[right] != target)    return -1;  return right;}滑动窗口算法框架: 123456789101112131415161718192021222324252627282930/* 滑动窗口算法框架 */void slidingWindow(string s, string t) {  unordered_map&lt;char, int&gt; need, window;  for (char c : t) need[c]++;  int left = 0, right = 0;  int valid = 0;  while (right &lt; s. size()) {    // c 是将移入窗口的字符    char c = s[right];    // 右移窗口    right++;    // 进行窗口内数据的一系列更新    . . .     /*** debug 输出的位置 ***/    printf( window: [%d, %d)\n , left, right);    /********************/    // 判断左侧窗口是否要收缩    while (window needs shrink) {      // d 是将移出窗口的字符      char d = s[left];      // 左移窗口      left++;      // 进行窗口内数据的一系列更新      . . .     }  }} 76. 最小覆盖子串回溯算法框架: 12345678910result = []def backtrack(路径, 选择列表):  if 满足结束条件:    result. add(路径)    return  for 选择 in 选择列表:    做选择    backtrack(路径, 选择列表)    撤销选择 51. N皇后 17. 电话号码的字母组合排序算法: 快速排序: 1234567891011121314151617  void QSort(vector&lt;int&gt; &amp;arr, int left, int right) {  	if (left &gt;= right) return;  	int low = left;  	int high = right;  	int key = arr[left];  	while (left &lt; right) {  		while (left &lt; right &amp;&amp; arr[right] &gt;= key) right--;  		arr[left] = arr[right];  		while (left &lt; right &amp;&amp; arr[left] &lt;= key) left++;  		arr[right] = arr[left];  	}  	arr[left] = key;  	QSort(arr, low, left - 1);  	QSort(arr, left + 1, high);  } 单点更新，范围查询，用线段树。范围更新，单独查询，用差分数组前缀和、差分数组: 前缀和:  前缀和主要适用的场景是原始数组不会被修改的情况下，频繁查询某个区间的累加和 12345678910111213141516171819class PrefixSum {public:  /* 输入一个数组，构造前缀和 */  PrefixSum(vector&lt;int&gt; nums) {    prefix. resize(nums. size() + 1);    // 计算 nums 的累加和    for (int i = 1; i &lt; prefix. size(); i++) {      prefix[i] = prefix[i - 1] + nums[i - 1];    }  }  /* 查询闭区间 [i, j] 的累加和 */  int query(int i, int j) {    return prefix[j + 1] - prefix[i];  }private:  // 前缀和数组  vector&lt;int&gt; prefix;};prefix[i] 就代表着 nums[0. . i-1] 所有元素的累加和，如果我们想求区间 nums[i. . j] 的累加和，只要计算 prefix[j+1] - prefix[i] 即可，而不需要遍历整个区间求和。 差分数组:  差分数组的主要适用场景是频繁对原始数组的某个区间的元素进行增减 题目：1109. 航班预订统计12345678910111213141516171819202122232425262728293031323334class Difference {public:  Difference(vector&lt;int&gt; nums) {    diff. resize(nums. size());    // 构造差分数组    diff[0] = nums[0];    for (int i = 1; i &lt; nums. size(); i++) {      diff[i] = nums[i] - nums[i - 1];    }  }  /* 给闭区间 [i,j] 增加 val（可以是负数）*/  void increment(int i, int j, int val) {    diff[i] += val;    if (j + 1 &lt; diff. size()) {      diff[j + 1] -= val;    }  }  vector&lt;int&gt; result() {    vector&lt;int&gt; res;    res. resize(diff. size());    // 根据差分数组构造结果数组    res[0] = diff[0];    for (int i = 1; i &lt; diff. size(); i++) {      res[i] = res[i - 1] + diff[i];    }    return res;  }private:  // 差分数组  vector&lt;int&gt; diff;};前缀树: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354class Trie {public:  /** Initialize your data structure here. */  Trie() {  }  /** Inserts a word into the trie. */  void insert(string word) {    Trie *node = this;    for (auto c : word) {      if (node-&gt;next[c - 'a'] == nullptr) {        node-&gt;next[c - 'a'] = new Trie();      }      node = node-&gt;next[c - 'a'];    }    node-&gt;isEnd = true;  }  /** Returns if the word is in the trie. */  bool search(string word) {    Trie *node = this;    for (auto c : word) {      if (node-&gt;next[c - 'a'] == nullptr) {        return false;      }      node = node-&gt;next[c - 'a'];    }    return node-&gt;isEnd;  }  /** Returns if there is any word in the trie that starts with the given prefix. */  bool startsWith(string prefix) {    Trie *node = this;    for (auto c : prefix) {      if (node-&gt;next[c - 'a'] == nullptr) {        return false;      }      node = node-&gt;next[c - 'a'];    }    return true;  }private:  bool isEnd = false;  Trie *next[26] = { nullptr };};/** * Your Trie object will be instantiated and called as such: * Trie* obj = new Trie(); * obj-&gt;insert(word); * bool param_2 = obj-&gt;search(word); * bool param_3 = obj-&gt;startsWith(prefix); */并查集: 12345678910111213141516171819202122232425262728293031323334353637class UnionFind {public:  UnionFind(int n) {    size = n;    parent. resize(n);    for (int i = 0; i &lt; size; i++) {      parent[i] = i;    }  }  int Find(int x) {      // 查找x的父节点    if (x != parent[x]) {      parent[x] = Find(parent[x]);  // 路径压缩    }    return parent[x];  }  void Union(int x, int y) {    x = Find(x);    y = Find(y);    parent[x] = y;  }  int Count() {    int count = 0;    for (int i = 0; i &lt; size; i++) {      if (parent[i] == i) {        count++;      }    }    return count;  }private:  int size = 0;  vector&lt;int&gt; parent;};LRU: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091https://leetcode-cn. com/problems/lru-cache/struct DLListNode {  int key;  int val;  DLListNode* prev;  DLListNode* next;  DLListNode(int k, int v) {    key = k;    val = v;    prev = nullptr;    next = nullptr;  }};class LRUCache {public:  LRUCache(int capacity) {    head = new DLListNode(0, 0);    tail = new DLListNode(0, 0);    head-&gt;next = tail;    tail-&gt;next = head;    size = capacity;  }  int get(int key) {    int val = -1;    if (nodes. count(key)) {      val = nodes[key]-&gt;val;      MoveToHead(nodes[key]);    }    return val;  }  void put(int key, int value) {    if (nodes. count(key)) {      DeleteNode(nodes[key]);      DLListNode* node = new DLListNode(key, value);      InsertHead(node);      nodes[key] = node;    } else {      DLListNode* node = new DLListNode(key, value);      if (nodes. size() == size) {        RemoveTail();      }      InsertHead(node);      nodes[key] = node;    }  }private:  void RemoveTail() {    DeleteNode(tail-&gt;prev);  }  void InsertHead(DLListNode* node) {    node-&gt;next = head-&gt;next;    node-&gt;prev = head;    head-&gt;next-&gt;prev = node;    head-&gt;next = node;  }  void DeleteNode(DLListNode* node) {    if (node) {      DLListNode* next = node-&gt;next;      node-&gt;prev-&gt;next = node-&gt;next;      node-&gt;next-&gt;prev = node-&gt;prev;      nodes. erase(node-&gt;key);      delete node;      node = nullptr;    }  }  void MoveToHead(DLListNode* node) {    node-&gt;prev-&gt;next = node-&gt;next;    node-&gt;next-&gt;prev = node-&gt;prev;    InsertHead(node);  }private:  int size = 0;  unordered_map&lt;int, DLListNode*&gt; nodes;  // key -&gt; node  DLListNode* head;  DLListNode* tail;};/** * Your LRUCache object will be instantiated and called as such: * LRUCache* obj = new LRUCache(capacity); * int param_1 = obj-&gt;get(key); * obj-&gt;put(key,value); */"
    }, {
    "id": 18,
    "url": "/OpenMP/",
    "title": "OpenMP",
    "body": "2020/04/17 - 原文链接：https://computing. llnl. gov/tutorials/openMP/ （原文已经没了） 1、摘要: OpenMP 是一个应用程序接口(API)，由一组主要的计算机硬件和软件供应商联合定义。OpenMP 为共享内存并行应用程序的开发人员提供了一个可移植的、可伸缩的模型。该API在多种体系结构上支持 C/C++ 和 Fortran。本教程涵盖了 OpenMP 3. 1 的大部分主要特性，包括用于指定并行区域、工作共享、同步和数据环境的各种构造和指令。还将讨论运行时库函数和环境变量。本教程包括 C 和 Fortran 示例代码以及一个实验练习。 水平/先决条件：本教程非常适合那些刚接触 OpenMP 并行编程的人。需要对 C 语言或 Fortran 语言中的并行编程有基本的了解。对于那些通常不熟悉并行编程的人来说，EC3500: 并行计算导论中的材料将会很有帮助。 2、简介: 2. 1、什么是OpenMP: OpenMP是：:  一种应用程序接口(API)，可用于显式地指示多线程、共享内存并行性。 由三个主要的API组件组成：     编译器指令   运行时库函数   环境变量    Open Multi-Processing的缩写OpenMP的目标:  标准化     在各种共享内存架构/平台之间提供一个标准。   由一组主要的计算机硬件和软件供应商联合定义和认可。    至精至简     为共享内存机器建立一组简单且有限的指令。   重要的并行性可以通过使用3或4个指令来实现。   显然，随着每个新版本的发布，这个目标变得越来越没有意义。    易用性     提供以增量方式并行化串行程序的能力，这与通常需要全有或全无方法的消息传递库不同。   提供实现粗粒度和细粒度并行的能力。    可移植性     为 C/C++ 和 FORTRAN 指定API。   大多数主要平台已经实现，包括Unix/Linux平台和Windows。   注意：本教程参考了OpenMP 3. 1版。新版本的语法和特性目前还没有涉及。 3、OpenMP编程模型: 3. 1、共享内存模型:  OpenMP是为多处理器或多核共享内存机器设计的。底层架构可以是共享内存 UMA 或 NUMA。      Uniform Memory Access 一致内存访问   Uniform Memory Access 非一致内存访问                因为OpenMP是为共享内存并行编程而设计的，所以它在很大程度上局限于单节点并行性。通常，节点上处理元素(核心)的数量决定了可以实现多少并行性。3. 2、在 HPC 中使用 OpenMP 的动机:  OpenMP本身的并行性仅限于单个节点。 对于高性能计算(HPC - High Performance Computing)应用程序，OpenMP 与 MPI 相结合以实现分布式内存并行。这通常被称为混合并行编程。     OpenMP 用于每个节点上的计算密集型工作。   MPI 用于实现节点之间的通信和数据共享。    这使得并行性可以在集群的整个范围内实现。      Hybrid OpenMP-MPI Parallelism            3. 3、基于线程的并行性:  OpenMP 程序仅通过使用线程来实现并行性。 执行线程是操作系统可以调度的最小处理单元。一种可以自动运行的子程序，这个概念可能有助于解释什么是线程。 线程存在于单个进程的资源中。没有这个进程，它们就不复存在。 通常，线程的数量与机器处理器/核心的数量相匹配。但是，线程的实际使用取决于应用程序。3. 4、显式并行性:  OpenMP 是一个显式的(而不是自动的)编程模型，为程序员提供了对并行化的完全控制。 并行化可以像获取串行程序和插入编译器指令一样简单… 或者像插入子程序来设置多个并行级别、锁甚至嵌套锁一样复杂3. 5、Fork - Join 模型:  OpenMP 使用并行执行的 fork-join 模型：  所有 OpenMP 程序都开始于一个主线程。主线程按顺序执行，直到遇到第一个并行区域结构。 FORK：主线程然后创建一组并行线程。 之后程序中由并行区域结构封装的语句在各个团队线程中并行执行。 JOIN：当团队线程完成并行区域结构中的语句时，它们将进行同步并终止，只留下主线程。 并行区域的数量和组成它们的线程是任意的。3. 6、数据范围:  因为 OpenMP 是共享内存编程模型，所以在默认情况下，并行区域中的大多数数据都是共享的。 一个并行区域中的所有线程都可以同时访问共享数据。 OpenMP 为程序员提供了一种方法，可以在不需要默认共享范围的情况下显式地指定数据的“作用域”。 数据范围属性子句将更详细地讨论这个主题。3. 7、嵌套的并行性:  该 API 提供了在其他并行区域内放置并行区域的方法。 实现可能支持这个特性，也可能不支持。3. 8、动态线程:  该 API 为运行时环境提供了动态更改线程数量的功能，这些线程用于执行并行区域。如有可能，旨在促进更有效地利用资源。 实现可能支持这个特性，也可能不支持。3. 9、I/O:  OpenMP 没有指定任何关于并行 I/O 的内容。如果多个线程试图从同一个文件进行写/读操作，这一点尤其重要。 如果每个线程都对不同的文件执行 I/O，那么问题就不那么重要了。 完全由程序员来确保在多线程程序的上下文中正确地执行 I/O。3. 10、内存模型：经常刷新？:  OpenMP 提供了线程内存的“宽松一致性”和“临时”视图(用他们的话说)。换句话说，线程可以“缓存”它们的数据，并且不需要始终与实际内存保持精确的一致性。 当所有线程以相同的方式查看共享变量非常重要时，程序员负责确保所有线程根据需要刷新该变量。4、OpenMP API 概述: 4. 1、三大构成:  OpenMP 3. 1 API 由三个不同的组件组成：     编译器指令   运行时库函数   环境变量    后来的一些 API 包含了这三个相同的组件，但是增加了指令、运行时库函数和环境变量的数量。 应用程序开发人员决定如何使用这些组件。在最简单的情况下，只需要其中的几个。 实现对所有 API 组件的支持各不相同。例如，一个实现可能声明它支持嵌套并行，但是 API 清楚地表明它可能被限制在一个线程上——主线程。不完全符合开发人员的期望？4. 2、编译器指令:  编译器指令在源代码中以注释的形式出现，编译器会忽略它们，除非您另外告诉它们 — 通常通过指定适当的编译标志，如后面的编译部分所述。 OpenMP 编译器指令用于各种目的：     生成一个并行区域   在线程之间划分代码块   在线程之间分配循环迭代   序列化代码段   线程之间的工作同步      编译器指令有以下语法：sentinel directive-name [clause, …]例如：   #pragma omp parallel default(shared) private(beta, pi)   后面将详细讨论编译器指令。4. 3、运行时库函数 Run-time Library Routines::  OpenMP API 包括越来越多的运行时库函数。 这些程序用于各种目的：     设置和查询线程的数量   查询线程的唯一标识符(线程ID)、父线程的标识符、线程团队大小   设置和查询动态线程特性   查询是否在一个并行区域，以及在什么级别   设置和查询嵌套并行性   设置、初始化和终止锁以及嵌套锁   查询 wall clock time 和分辨率      对于 C/C++，所有运行时库函数都是实际的子程序。对于Fortran来说，有些是函数，有些是子程序。例如：   #include  int omp_get_num_threads(void)   注意，对于C/C++，通常需要包含 &lt;omp. h &gt; 头文件。 运行时库函数将在运行时库函数一节中作为概述进行简要讨论，更多细节将在附录A中讨论。4. 4、环境变量:  OpenMP 提供了几个环境变量，用于在运行时控制并行代码的执行。 这些环境变量可以用来控制这些事情：     设置线程数   指定如何划分循环交互   将线程绑定到处理器   启用/禁用嵌套的并行性；设置嵌套并行度的最大级别   启用/禁用动态线程   设置线程堆栈大小   设置线程等待策略      设置 OpenMP 环境变量的方法与设置任何其他环境变量的方法相同，并且取决于您使用的是哪种 shell。例如：   csh/tcsh: setenv OMP_NUM_THREADS 8 sh/bash: export OMP_NUM_THREADS=8   稍后将在环境变量一节中讨论 OpenMP 环境变量。4. 5、OpenMP代码结构示例: 1234567891011121314151617181920212223242526272829#include &lt;omp. h&gt;main () {  int var1, var2, var3;  串行代码 `Serial code`   .   .   .   并行区域的开始。派生一组线程。 `Beginning of parallel region. Fork a team of threads. `  指定变量作用域 `Specify variable scoping `#pragma omp parallel private(var1, var2) shared(var3)  {    由所有线程执行的并行区域 `Parallel region executed by all threads`       .     其他 OpenMP 指令 `Other OpenMP directives`       .     运行时库调用 `Run-time Library calls`       .     所有线程加入主线程并解散 `All threads join master thread and disband`  }  恢复串行代码 `Resume serial code`   .   .   . }5、编译 OpenMP 程序:  OpenMP 版本依赖的 GCC 版本      OpenMP 版本   GCC版本         OpenMP 5. 0   &gt;= GCC 9. 1       OpenMP 4. 5   &gt;= GCC 6. 1       OpenMP 4. 0   &gt;= GCC 4. 9. 0       OpenMP 3. 1   &gt;= GCC 4. 7. 0       OpenMP 3. 0   &gt;= GCC 4. 4. 0       OpenMP 2. 5   &gt;= GCC 4. 2. 0    查看一系列编译器对 OpenMP 支持的最佳位置：https://www. openmp. org/resources/openmp-compilers-tools   linux 下编译命令示例：   g++ Test. cpp -o omptest -fopenmp  6、OpenMP 指令: 6. 1、C/C++ 指令格式: 格式:       #pragma omp   directive-name   [clause, …]   newline         所有 OpenMP C/C++ 指令都需要。   一个有效的 OpenMP 指令。必须出现在 pragma 之后和任何子句之前。   可选的。除非另有限制，子句可以按任何顺序重复。   必需的。在此指令所包含的结构化块之前。   示例: 1#pragma omp parallel default(shared) private(beta, pi)一般规则:  区分大小写。 指令遵循 C/C++ 编译器指令标准的约定。 每个指令只能指定一个指令名。 每个指令最多应用于一个后续语句，该语句必须是一个结构化块。 长指令行可以通过在指令行的末尾使用反斜杠(“\”)来转义换行符，从而在后续的行中“继续”。6. 2、指令范围: 静态(词法)范围:  在指令后面的结构化块的开始和结束之间以文本形式封装的代码。 指令的静态范围不跨越多个程序或代码文件。孤立的指令:  一个 OpenMP 指令，独立于另一个封闭指令，称为孤立型指令。它存在于另一个指令的静态(词法)范围之外。 将跨越程序和可能的代码文件。动态范围:  指令的动态范围包括静态(词法)范围和孤立指令的范围。为什么这很重要？:  OpenMP 为指令如何相互关联(绑定)和嵌套指定了许多范围规则。 如果忽略 OpenMP 绑定和嵌套规则，可能会导致非法或不正确的程序。 有关详细信息，请参阅指令绑定和嵌套规则。6. 3、并行区域结构: 目的:  并行区域是由多个线程执行的代码块。这是基本的 OpenMP 并行结构。格式: 1234567891011#pragma omp parallel [clause . . . ] newline           if (scalar_expression)           private (list)           shared (list)           default (shared | none)           firstprivate (list)           reduction (operator: list)           copyin (list)           num_threads (integer-expression)  structured_block注意:  当一个线程执行到一个并行指令时，它创建一个线程组并成为该线程组的主线程。主线程是该团队的成员，在该团队中线程号为0。 从这个并行区域开始，代码被复制，所有线程都将执行该代码。 在并行区域的末端有一个隐含的屏障。只有主线程在此之后继续执行。 如果任何线程在一个并行区域内终止，则团队中的所有线程都将终止，并且在此之前所做的工作都是未定义的。有多少线程:  并行区域内的线程数由以下因素决定，按优先级排序：     IF 子句的计算   NUM_THREADS 子句的设置   使用 omp_set_num_threads() 库函数   设置 OMP_NUM_THREADS 环境变量   实现缺省值 — 通常是一个节点上的 cpu 数量，尽管它可以是动态的(参见下一小节)    线程的编号从0(主线程)到N-1。动态线程:  使用 omp_get_dynamic() 库函数来确定是否启用了动态线程。 如果支持的话，启用动态线程的两种方法是：     omp_set_dynamic() 库函数   将 OMP_NESTED 环境变量设置为 TRUE    如果不支持，则在另一个并行区域内嵌套一个并行区域，从而在默认情况下创建一个由单个线程组成的新团队。子句:  IF 子句：如果存在，它的值必须为非零，以便创建一个线程组。否则，该区域将由主线程串行执行。 其余的子句稍后将在数据范围属性子句一节中详细描述。限制条件:  并行区域必须是不跨越多个程序或代码文件的结构化块。 从一个并行区域转入或转出是非法的。 只允许一个 IF 子句。 只允许一个 NUM_THREADS 子句。 程序不能依赖于子句的顺序。并行区域例子:  简单的“Hello World”程序     每个线程执行包含在并行区域中的所有代码。   OpenMP 库函数用于获取线程标识符和线程总数。    #include  #include  int main(int argc, char *argv[]) {   int nthreads, tid;   /* Fork a team of threads with each thread having a private tid variable */ #pragma omp parallel private(tid)   {     /* Obtain and print thread id */     tid = omp_get_thread_num();     printf( Hello World from thread = %d\n , tid);   1234567   /* Only master thread does this */   if (tid == 0) {     nthreads = omp_get_num_threads();     printf( Number of threads = %d\n , nthreads);   } } /* All threads join master thread and terminate */ return 0;  }   6. 4、工作共享结构:  工作共享结构将封闭代码区域的执行划分给遇到它的团队成员。 工作共享结构不会启动新线程。 在进入工作共享结构时没有隐含的屏障，但是在工作共享结构的末尾有一个隐含的屏障。工作共享结构的类型：:  DO / for - 整个团队的循环迭代。表示一种“数据并行性”。 SECTIONS - 把工作分成单独的、不连续的部分。每个部分由一个线程执行。可以用来实现一种“函数并行性”。 SINGLE - 序列化一段代码。      DO/for loop   SECTIONS   SINGLE                   限制条件:  为了使指令能够并行执行，必须将工作共享结构动态地封装在一个并行区域中。 团队的所有成员都必须遇到工作共享结构，或者根本不遇到。 团队的所有成员必须以相同的顺序遇到连续的工作共享结构。6. 4. 1、DO / for 指令: 目的 DO / for 指令指定紧随其后的循环迭代必须由团队并行执行。这假定已经启动了并行区域，否则它将在单个处理器上串行执行。格式12345678910111213141516171819202122232425#pragma omp for [clause . . . ] newline        schedule (type [,chunk])        ordered        private (list)        firstprivate (list)        lastprivate (list)        shared (list)        reduction (operator: list)        collapse (n)        nowait  for_loop ##### 子句 - **schedule**：描述循环迭代如何在团队中的线程之间进行分配。默认的调度是依赖于实现的。有关如何使一种调度比其他调度更优的讨论，请参见[http://openmp. org/forum/viewtopic. php?f=3&amp;t=83](#http://openmp. org/forum/viewtopic. php?f=3&amp;t=83) 。* 静态(STATIC) - 循环迭代被分成小块，然后静态地分配给线程。如果没有指定 chunk，则迭代是均匀地(如果可能)在线程之间连续地划分。 ![](https://upload-images. jianshu. io/upload_images/22782486-f76e413446e4e137. png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)* 动态(DYNAMIC) - 循环迭代分成小块，并在线程之间动态调度；当一个线程完成一个块时，它被动态地分配给另一个块。默认块大小为1。 ![](https://upload-images. jianshu. io/upload_images/22782486-32ede1eaa5604633. png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)* 引导(GUIDED) - 当线程请求迭代时，迭代被动态地分配给块中的线程，直到没有剩余的块需要分配为止。与 DYNAMIC 类似，只是每次将一个工作包分配给一个线程时，块的大小就会减小。&lt;br&gt;初始块的大小与 `number_of_iteration / number_of_threads` 成比例&lt;br&gt;后续块与`number_of_iterations_remaining / number_of_threads` 成比例&lt;br&gt;chunk 参数定义最小块大小。默认块大小为1。&lt;br&gt;注意：编译器的实现方式不同，如下面的“Guided A”和“Guided B”示例所示。&lt;br&gt; ![](https://upload-images. jianshu. io/upload_images/22782486-59fb784a811f9df6. png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)* 运行时(RUNTIME) - 环境变量 `OMP_SCHEDULE` 将调度决策延迟到运行时。为这个子句指定块大小是非法的。* 自动(AUTO) - 调度决策被委托给编译器或运行时系统。   nowait： 如果指定，那么线程在并行循环结束时不会同步。     ordered：指定循环的迭代必须像在串行程序中一样执行。     collapse：指定在一个嵌套循环中有多少个循环应该折叠成一个大的迭代空间，并根据 schedule 子句进行划分。折叠迭代空间中的迭代的顺序是确定的，就好像它们是按顺序执行的一样。可能会提高性能。     其他子句稍后将在数据范围属性子句一节中详细描述。  限制条件 DO 循环不能是 DO WHILE 循环，也不能是没有循环控制的循环。此外，循环迭代变量必须是整数，并且对于所有线程，循环控制参数必须相同。 程序的正确性不能依赖于哪个线程执行特定的迭代。 在与 DO / for 指令关联的循环中跳转（转到）是非法的。 块大小必须指定为循环不变的整数表达式，因为在不同线程求值期间不存在同步。 ORDERED、COLLAPSE、SCHEDULE 子句可以出现一次。 有关其他限制，请参阅 OpenMP 规范文档。DO / for 指令示例 简单的 vector 相加程序     数组 A、B、C 和变量 N 将由所有线程共享。   变量 i 对每个线程都是私有的；每个线程都有自己唯一的副本。   循环迭代将在 CHUNK 大小的块中动态分布。   线程在完成各自的工作后将不会同步 (NOWAIT)。    #include  #define N 1000 #define CHUNKSIZE 100   int main(int argc, char *argv[]) {   int i, chunk;   float a[N], b[N], c[N];   1234 /* Some initializations */ for (i = 0; i &lt; N; i++)   a[i] = b[i] = i * 1. 0; chunk = CHUNKSIZE;    #pragma omp parallel shared(a,b,c,chunk) private(i)   {   #pragma omp for schedule(dynamic,chunk) nowait     for (i = 0; i &lt; N; i++)       c[i] = a[i] + b[i];   123 } /* end of parallel region */ return 0;  }   6. 4. 2 sections 指令: 目的 sections 指令是一个非迭代的工作共享结构。它指定所包含的代码段将被分配给团队中的各个线程。 独立的 section 指令嵌套在 sections 指令中。每个部分由团队中的一个线程执行一次。不同的部分可以由不同的线程执行。如果一个线程执行多个部分的速度足够快，并且实现允许这样做，那么它就可以执行多个部分。格式123456789101112#pragma omp sections [clause . . . ] newline           private (list)           firstprivate (list)           lastprivate (list)           reduction (operator: list)           nowait { #pragma omp section  newline   structured_block #pragma omp section  newline   structured_block }子句 除非使用了 NOWAIT/nowait 子句，否则在 sections 指令的末尾有一个隐含的屏障（译者注：an implied barrier 意思应该是线程会相互等待）。 稍后将在数据范围属性子句一节中详细描述子句。限制条件 跳转（转到）或跳出 section 代码块是非法的。 section 指令必须出现在一个封闭的 sections 指令的词法范围内(没有独立部分)。sections 指令示例   下面一个简单的程序演示不同的工作块将由不同的线程完成。   #include  #define N 1000   int main() {   int i;   float a[N], b[N], c[N], d[N];   12345 /* Some initializations */ for (i = 0; i &lt; N; i++) {   a[i] = i * 1. 5;   b[i] = i + 22. 35; }    #pragma omp parallel shared(a,b,c,d) private(i)   { #pragma omp sections nowait     { #pragma omp section       for (i = 0; i &lt; N; i++)         c[i] = a[i] + b[i];   #pragma omp section       for (i = 0; i &lt; N; i++)         d[i] = a[i] * b[i];     } /* end of sections /   } / end of parallel region */   return 0; }  6. 4. 3 single 指令: 目的 single 指令指定所包含的代码仅由团队中的一个线程执行。 在处理非线程安全的代码段(如 I/O )时可能很有用格式123456#pragma omp single [clause . . . ] newline          private (list)          firstprivate (list)          nowait   structured_block子句 除非指定了 nowait 子句，否则团队中不执行 single 指令的线程将在代码块的末尾等待。 稍后将在数据范围属性子句一节中详细描述子句。限制条件 进入或跳出一个 single 代码块是非法的。6. 5 合并并行工作共享结构:  OpenMP 提供了三个简单的指令：     parallel for   parallel sections   PARALLEL WORKSHARE (fortran only)    在大多数情况下，这些指令的行为与单独的并行指令完全相同，并行指令后面紧跟着一个单独的工作共享指令。 大多数适用于这两个指令的规则、条款和限制都是有效的。有关详细信息，请参阅 OpenMP API。   下面显示了一个使用 parallel for 组合指令的示例。   #include  #define N    1000 #define CHUNKSIZE  100   int main() {   int i, chunk;   float a[N], b[N], c[N];   1234 /* Some initializations */ for (i = 0; i &lt; N; i++)   a[i] = b[i] = i * 1. 0; chunk = CHUNKSIZE;    #pragma omp parallel for shared(a,b,c,chunk) private(i) schedule(static,chunk)   for (i = 0; i &lt; N; i++)     c[i] = a[i] + b[i];   return 0; }  6. 6 任务结构: 目的:  任务结构定义了一个显式任务，该任务可以由遇到的线程执行，也可以由团队中的任何其他线程延迟执行。 任务的数据环境由数据共享属性子句确定。 任务执行取决于任务调度 — 详细信息请参阅 OpenMP 3. 1 规范文档 有关 taskyield 和 taskwait 指令，请参阅 OpenMP 3. 1 文档。格式: 1234567891011#pragma omp task [clause . . . ] newline         if (scalar expression)         final (scalar expression)         untied         default (shared | none)         mergeable         private (list)         firstprivate (list)         shared (list)  structured_block子句和限制条件:  详细信息请参阅 OpenMP 3. 1 规范文档。6. 7 同步结构:  考虑一个简单的例子，两个线程都试图同时更新变量x：      THREAD1   THREAD2         update(x){    x = x + 1}x = 0update(x)print(x)   update(x){    x = x + 1}x = 0update(x)print(x)    一种可能的执行顺序：     线程1初始化 x 为0并调用   线程1将 x 加1，x 现在等于1   线程2初始化 x 为0并调用 update(x)，x现在等于0   线程1输出 x，它等于0而不是1   线程2将 x 加1，x 现在等于1   线程2打印 x 为1    为了避免这种情况，必须在两个线程之间同步 x 的更新，以确保产生正确的结果。 OpenMP 提供了各种同步结构，这些构造控制每个线程相对于其他团队线程的执行方式。6. 7. 1 master 指令: 目的 master 指令指定了一个区域，该区域只由团队的主线程执行。团队中的所有其他线程都将跳过这部分代码。 这个指令没有隐含的障碍( implied barrier )。格式12#pragma omp master newline  structured_block限制条件 进入或跳出一个 master 代码块是非法的。6. 7. 2 critical 指令: 目的 critical 指令指定了一个只能由一个线程执行的代码区域。格式12#pragma omp critical [ name ] newline  structured_block注意事项 如果一个线程当前在一个 critical 区域内执行，而另一个线程到达该 critical 区域并试图执行它，那么它将阻塞，直到第一个线程退出该 critical 区域。 可选的名称使多个不同的临界区域存在：     名称充当全局标识符。具有相同名称的不同临界区被视为相同的区域。   所有未命名的临界段均视为同一段。   限制条件 进入或跳出一个 critical 代码块是非法的。 Fortran only: The names of critical constructs are global entities of the program. If a name conflicts with any other entity, the behavior of the program is unspecified. critical 结构示例   团队中的所有线程都将尝试并行执行，但是由于 x 的增加由 critical 结构包围，在任何时候只有一个线程能够读/增量/写 x。   #include   int main() {   int x;   x = 0;   #pragma omp parallel shared(x)   { #pragma omp critical     x = x + 1;   } /* end of parallel region */   return 0; }  6. 7. 3 barrier 指令: 目的 barrier 指令同步团队中的所有线程。 当到达 barrier 指令时，一个线程将在该点等待，直到所有其他线程都到达了 barrier 指令。然后，所有线程继续并行执行 barrier 之后的代码。格式1#pragma omp barrier newline限制条件 团队中的所有线程(或没有线程)都必须执行 barrier 区域。 对于团队中的每个线程，遇到的 work-sharing 区域和 barrier 区域的顺序必须是相同的。6. 7. 4 taskwait 指令: 目的 OpenMP 3. 1 特性 taskwait 结构指定自当前任务开始以来生成的子任务完成时的等待时间。格式1#pragma omp taskwait newline限制条件 因为 taskwait 结构是一个独立的指令，所以它在程序中的位置有一些限制。taskwait 指令只能放置在允许使用基本语言语句的地方。taskwait 指令不能代替 if、while、do、switch 或 label 后面的语句。有关详细信息，请参阅 OpenMP 3. 1 规范文档。6. 7. 5 atomic 指令: 目的 atomic 结构确保以原子方式访问特定的存储位置，而不是将其暴露给多个线程同时读写，这些线程可能会导致不确定的值。本质上，这个指令提供了一个最小临界( mini-CRITICAL )区域。格式12#pragma omp atomic [ read | write | update | capture ] newline  statement_expression限制条件 该指令仅适用于紧接其后的单个语句。 原子语句必须遵循特定的语法。查看最新的OpenMP规范。6. 7. 6 flush 指令: 目的 flush 指令标识了一个同步点，在这个点上，内存数据必须一致。这时，线程可见的变量被写回内存。 请参阅最新的 OpenMP 规范以获取详细信息。格式1#pragma omp flush (list) newline注意事项 可选 list 参数包含一个将被刷新的已命名变量列表，以避免刷新所有变量。对于列表中的指针，请注意指针本身被刷新，而不是它指向的对象。 实现必须确保线程可见变量的任何修改在此之后对所有线程都是可见的，例如编译器必须将值从寄存器恢复到内存，硬件可能需要刷新写缓冲区，等等。 对于下面的指令，将使用 flush 指令。如果存在 nowait 子句，则该指令无效。     barrier   parallel - 进入和退出   critical - 进入和退出   ordered - 进入和退出   for - 退出   sections - 退出   single - 退出   6. 7. 7 ordered 指令: 目的 ordered 指令指定封闭的循环迭代将以串行处理器上执行顺序执行。 如果之前的迭代还没有完成，线程在执行它们的迭代块之前需要等待。 在带有 ordered 子句的 for 循环中使用。 ordered 指令提供了一种“微调”的方法，其中在循环中应用了排序。否则，它不是必需的。格式123456#pragma omp for ordered [clauses. . . ]  (loop region)#pragma omp ordered newline  structured_block  (endo of loop region)限制条件 一个 ordered 指令只能在以下指令的动态范围内出现：     for 或者 parallel for (C/C++)。    在一个有序的区段中，任何时候都只允许一个线程。 进入或跳出一个 ordered 代码块是非法的。 一个循环的迭代不能多次执行同一个有序指令，也不能一次执行多个有序指令。 包含有序指令的循环必须是带有 ordered 子句的循环。6. 8 threadprivate 指令: 目的:  threadprivate 指令指定复制变量，每个线程都有自己的副本。 可用于通过执行多个并行区域将全局文件作用域变量(C/C++/Fortran)或公共块(Fortran)局部化并持久化到一个线程。格式: 1#pragma omp threadprivate (list)注意事项:  指令必须出现在列出的变量/公共块的声明之后。每个线程都有自己的变量/公共块的副本，所以一个线程写的数据对其他线程是不可见的。 在第一次进入一个并行区域时，应该假设 threadprivate 变量和公共块中的数据是未定义的，除非在并行指令中指定了 copyin 子句。 threadprivate 变量不同于 private 变量(稍后讨论)，因为它们能够在代码的不同并行区域之间持久存在。示例: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#include &lt;stdio. h&gt;#include &lt;omp. h&gt;int a, b, i, tid;float x;#pragma omp threadprivate(a, x)int main() {  /* 显式关闭动态线程 Explicitly turn off dynamic threads */  omp_set_dynamic(0);  printf( 1st Parallel Region:\n );#pragma omp parallel private(b,tid)  {    tid = omp_get_thread_num();    a = tid;    b = tid;    x = 1. 1 * tid + 1. 0;    printf( Thread %d:  a,b,x= %d %d %f\n , tid, a, b, x);  } /* end of parallel region */  printf( ************************************\n );  printf( Master thread doing serial work here\n );  printf( ************************************\n );  printf( 2nd Parallel Region:\n );#pragma omp parallel private(tid)  {    tid = omp_get_thread_num();    printf( Thread %d:  a,b,x= %d %d %f\n , tid, a, b, x);  } /* end of parallel region */  return 0;}Output:1st Parallel Region:Thread 4:  a,b,x= 4 4 5. 400000Thread 7:  a,b,x= 7 7 8. 700000Thread 2:  a,b,x= 2 2 3. 200000Thread 3:  a,b,x= 3 3 4. 300000Thread 6:  a,b,x= 6 6 7. 600000Thread 1:  a,b,x= 1 1 2. 100000Thread 5:  a,b,x= 5 5 6. 500000Thread 0:  a,b,x= 0 0 1. 000000************************************Master thread doing serial work here************************************2nd Parallel Region:Thread 1:  a,b,x= 1 0 2. 100000Thread 6:  a,b,x= 6 0 7. 600000Thread 4:  a,b,x= 4 0 5. 400000Thread 5:  a,b,x= 5 0 6. 500000Thread 2:  a,b,x= 2 0 3. 200000Thread 7:  a,b,x= 7 0 8. 700000Thread 0:  a,b,x= 0 0 1. 000000Thread 3:  a,b,x= 3 0 4. 300000限制条件:  只有在动态线程机制“关闭”并且不同并行区域中的线程数量保持不变的情况下，threadprivate 对象中的数据才能保证持久。动态线程的默认设置是未定义的。 Fortran: common block names must appear between slashes: /cb/ 有关这里没有列出的其他限制，请参阅最新的 OpenMP 规范。6. 9 数据范围属性子句:  也称为数据共享属性子句。 OpenMP 编程的一个重要考虑是理解和使用数据作用域。 因为 OpenMP 是基于共享内存编程模型的，所以大多数变量在默认情况下是共享的。 全局变量包括：     Fortran: COMMON blocks, SAVE variables, MODULE variables   文件作用域变量，static    私有变量包括：     循环索引变量   从并行区域调用的子程序中的堆栈变量   Fortran: Automatic variables within a statement block    OpenMP 数据范围属性子句用于显式定义变量的范围。它们包括：     private   firstprivate   lastprivate   shared   default   reduction   copyin    数据范围属性子句与几个指令（parallel、DO/for 和 sections）一起使用，以控制所包含变量的范围。 这些结构提供了在并行结构执行期间控制数据环境的能力。     它们定义了如何将程序的串行部分中的哪些数据变量传输到程序的并行区域(以及向后传输)   它们定义哪些变量将对并行区域中的所有线程可见，哪些变量以私有形式分配给所有线程。    数据范围属性子句仅在其词法/静态范围内有效。 重要事项：请参阅最新的 OpenMP 规范，以了解关于此主题的重要细节和讨论。 为了方便起见，提供了一个子句/指令汇总表。6. 9. 1 private 子句: 目的 private 子句将在其列表中的变量声明为每个线程的私有变量。格式1private (list)注意事项 私有变量的行为如下：     为团队中的每个线程声明一个相同类型的新对象   所有对原始对象的引用都被替换为对新对象的引用   应该假定每个线程都没有初始化   6. 9. 2 shared 子句: 目的 shared 子句声明其列表中的变量在团队中的所有线程之间共享。格式1shared (list)注意事项 共享变量只存在于一个内存位置，所有线程都可以读写该地址 程序员有责任确保多个线程正确地访问共享变量(例如通过临界区)6. 9. 3 default 子句: 目的 default 子句允许用户为任何并行区域的词法范围内的所有变量指定默认作用域。格式1default (shared | none)注意事项 使用 private、shared、firstprivate、lastprivate 和 reduction 子句可以避免使用特定变量。 C/C++ OpenMP 规范不包括将 private 或 firstprivate 作为可能的默认值。但是，实际的实现可能会提供这个选项。 使用 none 作为默认值要求程序员显式地限定所有变量的作用域。限制条件 在并行指令上只能指定一个 default 子句6. 9. 4 firstprivate 子句: 目的 firstprivate 子句将 private 子句的行为与它的列表中变量的自动初始化相结合。格式1firstprivate (list)注意事项 在进入并行或工作共享结构之前，将根据其原始对象的值初始化列出的变量。6. 9. 5 lastprivate 子句: 目的 lastprivate 子句将 private 子句的行为与从最后一个循环迭代或部分到原始变量对象的复制相结合。格式1lastprivate (list)注意事项 复制回原始变量对象的值是从封闭结构的最后一次(顺序)迭代或部分获得的。 例如，为 DO 部分执行最后一次迭代的团队成员，或者执行 sections 上下文的最后一部分的团队成员，使用其自身的值执行副本。6. 9. 6 copyin 子句: 目的 copyin 子句提供了为团队中的所有线程分配相同值的 threadprivate 变量的方法。格式1copyin (list)注意事项 列表包含要复制的变量的名称。在Fortran中，列表既可以包含公共块的名称，也可以包含已命名变量的名称。 主线程变量用作复制源。在进入并行结构时，将使用其值初始化团队线程。6. 9. 7 copyprivate 子句: 目的 copyprivate 子句可用于将单个线程获得的值直接传播到其他线程中私有变量的所有实例。 与 single 指令相关联 有关更多的讨论和示例，请参阅最新的 OpenMP 规范文档。格式1copyprivate (list)6. 9. 8 reduction 子句: 目的 reduction 子句对出现在其列表中的变量执行约简操作。 为每个线程创建并初始化每个列表变量的私有副本。在约简结束时，将约简变量应用于共享变量的所有私有副本，并将最终结果写入全局共享变量。格式1reduction (operator: list)Example: REDUCTION - Vector Dot Product: 并行循环的迭代将以相同大小的块分配给团队中的每个线程(调度静态)   在并行循环构造的末尾，所有线程将添加它们的“result”值来更新主线程的全局副本。   #include  #include   int main() {   int i, n, chunk;   float a[100], b[100], result;   12345678 /* Some initializations */ n = 100; chunk = 10; result = 0. 0; for (i = 0; i &lt; n; i++) {   a[i] = i * 1. 0;   b[i] = i * 2. 0; }    #pragma omp parallel for default(shared) private(i)    schedule(static,chunk) reduction(+:result)   for (i = 0; i &lt; n; i++)     result = result + (a[i] * b[i]);   12 printf( Final result= %f\n , result); return 0;  }   限制条件 列表项的类型必须对约简操作符有效。 列表项/变量不能声明为共享或私有。 约简操作可能与实数无关。 有关其他限制，请参见 OpenMP 标准 API。6. 10 子句/指令汇总表:  下表总结了哪些子句被哪些OpenMP指令接受。      Clause   parallel   for   sections   single   parallel for   parallel sections         if   √               √   √       private   √   √   √   √   √   √       shared   √   √           √   √       default   √               √   √       firstprivate   √   √   √   √   √   √       lastprivate       √   √       √   √       reduction   √   √   √       √   √       copyin   √               √   √       copyprivate               √               schedule       √           √           ordered       √           √           nowait       √   √   √            以下 OpenMP 指令不接受子句：     master   critical   barrier   atomic   flush   ordered   threadprivate    实现可能(也确实)与每个指令所支持的子句的标准不同。6. 11 指令绑定和嵌套规则:  本节主要是作为管理 OpenMP 指令和绑定的规则的快速参考。用户应该参考他们的实现文档和 OpenMP 标准以了解其他规则和限制。 除非另有说明，规则适用于 Fortran 和 C/C++ OpenMP 实现。 注意：Fortran API 还定义了许多数据环境规则。这些没有在这里复制。指令绑定:  DO/for、sections、single、master 和 barrier 指令绑定到动态封闭的 parallel (如果存在的话)。如果当前没有并行区域被执行，指令就没有效果。 有序指令绑定到动态封闭的 DO/for 。 atomic 指令强制对所有线程中的 atomic 指令进行独占访问，而不仅仅是当前的团队。 critical 指令强制对所有线程中的 critical 指令进行独占访问，而不仅仅是当前的团队。 指令永远不能绑定到最接近的封闭并行之外的任何指令。指令嵌套:  工作共享区域不能紧密嵌套在工作共享、显式任务、关键区域、有序区域、原子区域或主区域内。 屏障区域不能紧密嵌套在工作共享、显式任务、关键区域、有序区域、原子区域或主区域中。 主区域不能紧密嵌套在工作共享、原子或显式任务区域内。 有序区域可能不会紧密嵌套在临界、原子或显式任务区域内。 一个有序区域必须与一个有序子句紧密嵌套在一个循环区域(或并行循环区域)内。 临界区不能嵌套(紧密嵌套或以其他方式嵌套)在具有相同名称的临界区内。注意，此限制不足以防止死锁。 并行、刷新、临界、原子、taskyield 和显式任务区域可能不会紧密嵌套在原子区域内。7、运行时库函数: 概述:  OpenMP API 包括越来越多的运行时库函数。 这些函数有多种用途，如下表所示：      Routine   Purpose         opm_set_num_threads   设置将在下一个并行区域中使用的线程数       opm_get_num_threads   返回当前在团队中执行并行区域的线程数，该区域是调用该线程的地方       opm_get_max_threads   返回可通过调用 opm_get_num_threads 函数返回的最大值       opm_get_thread_num   返回在团队中执行此调用的线程的线程号       opm_get_thread_limit   返回程序可用的 OpenMP 线程的最大数量       opm_get_num_procs   返回程序可用的处理器数量       opm_in_parallel   用于确定正在执行的代码段是否并行       opm_set_dynamic   启用或禁用(由运行时系统)可用于执行并行区域的线程数的动态调整       opm_get_dynamic   用于确定是否启用动态线程调整       opm_set_nested   用于启用或禁用嵌套并行性       opm_get_nested   用于确定是否启用嵌套并行性       opm_set_schedule   在 OpenMP 指令中将“runtime”用作调度类型时，设置循环调度策略       opm_get_schedule   当 OpenMP 指令中使用“runtime”作为调度类型时，返回循环调度策略       opm_set_max-active_levels   设置嵌套并行区域的最大数目       opm_get_max-active_levels   返回嵌套并行区域的最大数目       opm_get_level   返回嵌套并行区域的当前级别       opm_get_ancestor_thread_num   对于当前线程的给定嵌套级别，返回祖先线程的线程数       opm_get_team_size   对于当前线程的给定嵌套级别，返回线程团队的大小       opm_get_active_level   返回包含调用的任务的嵌套活动并行区域的数目       opm_in_final   如果程序在最后一个任务区域执行，则返回true；否则返回false       opm_init_lock   初始化与锁变量关联的锁       opm_destory_lock   将给定的锁变量与任何锁分离       opm_set_lock   获得锁的所有权       opm_unset_lock   释放锁       opm_test_lock   尝试设置锁，但如果锁不可用，则不会阻塞       opm_init_nest_lock   初始化与锁变量关联的嵌套锁       opm_destory_nest_lock   将给定的嵌套锁变量与任何锁分离       opm_set_nest_lock   获取嵌套锁的所有权       opm_unset_nest_lock   释放嵌套锁       opm_test_nest_lock   尝试设置嵌套锁，但如果锁不可用，则不会阻塞       opm_get_wtime   提供便携式挂钟定时程序       opm_get_wtick   返回一个双精度浮点值，该值等于连续时钟滴答之间的秒数      对于C/C++，所有运行时库函数都是实际的子程序。对于Fortran来说，有些是函数，有些是子程序。例如:   #include  int omp_get_num_threads(void)   注意，对于C/C++，通常需要包含 &lt;omp. h &gt; 头文件。 Fortran例程不区分大小写，但C/C++例程区分大小写。 对于锁程序/函数：     锁变量只能通过锁程序访问   对于Fortran，锁变量的类型应该是integer，并且要足够大，以便容纳一个地址。   对于C/C++，lock 变量的类型必须是 omp_lock_t 或 omp_nest_lock_t ，这取决于所使用的函数。    实现注意事项：     实现可能支持也可能不支持所有 OpenMP API 特性。例如，如果支持嵌套并行，那么它可能只是名义上的，因为嵌套并行区域可能只有一个线程。   有关详细信息，请参阅您的实现文档—或者亲自试验一下，如果您在文档中找不到它，请自己查找。    运行时库函数在附录A中有更详细的讨论。8、环境变量:  OpenMP 提供了以下环境变量来控制并行代码的执行。 所有环境变量名都是大写的。分配给它们的值不区分大小写。OMP_SCHEDULE: 只适用于 DO, PARALLEL DO (Fortran)和 for , parallel for (C/C++)指令，它们的 schedule 子句设置为运行时。此变量的值决定如何在处理器上调度循环的迭代。例如： 12setenv OMP_SCHEDULE  guided, 4 setenv OMP_SCHEDULE  dynamic OMP_NUM_THREADS: 设置执行期间使用的最大线程数。例如： 1setenv OMP_NUM_THREADS 8OMP_DYNAMIC: 启用或禁用可用于并行区域执行的线程数量的动态调整。有效值为 TRUE 或 FALSE。例如： 1setenv OMP_DYNAMIC TRUEOMP_PROC_BIND: 启用或禁用线程绑定到处理器。有效值为 TRUE 或 FALSE。例如： 1setenv OMP_PROC_BIND TRUEOMP_NESTED: 启用或禁用嵌套并行性。有效值为 TRUE 或 FALSE。例如： 1setenv OMP_NESTED TRUEOMP_STACKSIZE: 控制已创建(非主)线程的堆栈大小。例子: 1234567setenv OMP_STACKSIZE 2000500Bsetenv OMP_STACKSIZE  3000 k  setenv OMP_STACKSIZE 10Msetenv OMP_STACKSIZE   10 M  setenv OMP_STACKSIZE  20 m  setenv OMP_STACKSIZE   1G setenv OMP_STACKSIZE 20000OMP_WAIT_POLICY: 为 OpenMP 实现提供有关等待线程的所需行为的提示。一个兼容的 OpenMP 实现可能遵守也可能不遵守环境变量的设置。有效值分为 ACTIVE 和 PASSIVE。ACTIVE 指定等待的线程大部分应该是活动的，即，在等待时消耗处理器周期。PASSIVE 指定等待的线程大部分应该是被动的，即，而不是在等待时消耗处理器周期。ACTIVE 和 PASSIVE 行为的细节是由实现定义的。例子: 1234setenv OMP_WAIT_POLICY ACTIVEsetenv OMP_WAIT_POLICY activesetenv OMP_WAIT_POLICY PASSIVEsetenv OMP_WAIT_POLICY passiveOMP_MAX_ACTIVE_LEVELS: 控制嵌套的活动并行区域的最大数目。该环境变量的值必须是非负整数。如果 OMP_MAX_ACTIVE_LEVELS 的请求值大于实现所能支持的嵌套活动并行级别的最大数量，或者该值不是一个非负整数，则该程序的行为是由实现定义的。例子: 1setenv OMP_MAX_ACTIVE_LEVELS 2OMP_THREAD_LIMIT: 设置用于整个 OpenMP 程序的 OpenMP 线程的数量。这个环境变量的值必须是正整数。如果 OMP_THREAD_LIMIT 的请求值大于实现所能支持的线程数，或者该值不是正整数，则程序的行为是由实现定义的。例子： 1setenv OMP_THREAD_LIMIT 89、线程堆栈大小和线程绑定: 线程堆栈大小:  OpenMP 标准没有指定一个线程应该有多少堆栈空间。因此，默认线程堆栈大小的实现将有所不同。 默认的线程堆栈大小很容易耗尽。它也可以在编译器之间不可移植。以过去版本的LC编译器为例：      Compiler   Approx. Stack Limit   Approx. Array Size (doubles)         Linux icc, ifort   4 MB   700 x 700       Linux pgcc, pgf90   8 MB   1000 x 1000       Linux gcc, gfortran   2 MB   500 x 500    超出其堆栈分配的线程可能存在或不存在段错误。当数据被破坏时，应用程序可以继续运行。 静态链接代码可能受到进一步的堆栈限制。 用户的登录shell还可以限制堆栈大小   如果您的 OpenMP 环境支持 OpenMP 3. 0 OMP_STACKSIZE 环境变量(在前一节中介绍过)，那么您可以使用它在程序执行之前设置线程堆栈大小。例如：   setenv OMP_STACKSIZE 2000500B setenv OMP_STACKSIZE “3000 k “ setenv OMP_STACKSIZE 10M setenv OMP_STACKSIZE “ 10 M “ setenv OMP_STACKSIZE “20 m “ setenv OMP_STACKSIZE “ 1G” setenv OMP_STACKSIZE 20000   否则，在LC上，您应该能够对Linux集群使用下面的方法。该示例显示将线程堆栈大小设置为12 MB，作为预防措施，将shell堆栈大小设置为无限制。      env   cmd         csh/tcsh   setenv KMP_STACKSIZE 12000000limit stacksize unlimited       ksh/sh/bash   export KMP_STACKSIZE=12000000ulimit -s unlimited   线程绑定:  在某些情况下，如果一个程序的线程被绑定到处理器/核心，那么它的性能会更好。 “绑定”一个线程到一个处理器意味着操作系统将调度一个线程始终在同一个处理器上运行。否则，可以将线程调度为在任何处理器上执行，并在每个时间片的处理器之间来回“弹回”。 也称为“线程关联性”或“处理器关联性”。 将线程绑定到处理器可以更好地利用缓存，从而减少昂贵的内存访问。这是将线程绑定到处理器的主要动机。 根据平台、操作系统、编译器和 OpenMP 实现的不同，可以通过几种不同的方式将线程绑定到处理器。   OpenMP 3. 1 版 API 提供了一个环境变量来“打开”或“关闭”处理器绑定。例如：   setenv OMP_PROC_BIND TRUE setenv OMP_PROC_BIND FALSE   在更高的级别上，进程也可以绑定到处理器。 有关进程和线程绑定到LC Linux集群上的处理器的详细信息，可以在https://lc. llnl. gov/confluence/display/TLCC2/mpibind找到。10、Monitoring, Debugging and Performance Analysis Tools for OpenMP: 11、References and More Information: 12、附录A: 问题记录:  编译程序成功，执行程序报错：. /a. out: /usr/lib64/libgomp. so. 1: version `GOMP_4. 5’ not found (required by . /a. out)     原因是libgomp. so. 1版本不对    解决方法：  查找libgomp. so. 1  123 [root@localhost bin]## find /usr -name libgomp. so. 1   /usr/local/lib64/libgomp. so. 1   /usr/lib64/libgomp. so. 1    是否包含 GOMP_4. 5  12 strings /usr/local/lib64/libgomp. so. 1 | grep GOMP strings /usr/lib64/libgomp. so. 1 | grep GOMP    发现 /usr/local/lib64/libgomp. so. 1 包含 GOMP_4. 5 ，/usr/lib64/libgomp. so. 1 不包含 GOMP_4. 5，用包含GOMP_4. 5的so进行替换  1 cp /usr/local/lib64/libgomp. so. 1 /usr/lib64/libgomp. so. 1   "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );

    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}

$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});